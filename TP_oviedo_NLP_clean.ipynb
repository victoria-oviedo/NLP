{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PC5-0IITx7W_"
   },
   "source": [
    "## EJERCICIO 1 : Se carga el epositorio de Tiny Towns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M1Dpyc7TN3it",
    "outputId": "4fd0eb0d-3d68-4faa-8597-d8cdd63c4df8"
   },
   "outputs": [],
   "source": [
    "# Clonar el repositorio completo\n",
    "!git clone https://github.com/Augusto-Rabbia/NLP_TP1.git\n",
    "\n",
    "\n",
    "import os\n",
    "os.chdir(\"NLP_TP1/datos\")\n",
    "\n",
    "# Verificar contenido\n",
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iIAAWkhfycYz"
   },
   "source": [
    "## EJERCICIO 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QAu5yvTpywIM"
   },
   "source": [
    "### Selección y limpieza de texto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kvNtL2QCy80N"
   },
   "source": [
    "Para este ejercicio se selecciononaron todos les textos en español de la sección información y se concatenaron en un solo texto para que asi sea más extenso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pQSIGezZ54tJ",
    "outputId": "2f519e74-fc65-42f4-c978-108acf024cd9"
   },
   "outputs": [],
   "source": [
    "# Carga textos en español: review_bgg + review_externa + video\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "carpeta = \"/content/NLP_TP1/datos/informacion\"\n",
    "\n",
    "archivos_en = [\"review_bgg.txt\", \"review_externa.txt\", \"video4.txt\"]\n",
    "texto_total = \"\"\n",
    "for archivo in archivos_en:\n",
    "    with open(os.path.join(carpeta, archivo), \"r\", encoding=\"utf-8\") as f:\n",
    "        texto_total += f.read() + \"\\n\"\n",
    "\n",
    "\n",
    "print(f\"Total de caracteres: {len(texto_total)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M8nIhT4K08PL"
   },
   "source": [
    "Se hace una limpieza ligera de los datos ya que luego vamos a utilizar S-BERT y al eliminar puntuación o normalizar demasiado, se corre el riesgo de quitarle contexto al modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ya8WOtPggqzG"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def limpiar_texto(texto):\n",
    "    texto = re.sub(r'\\s+', ' ', texto)  # reemplazar múltiples espacios y saltos de línea\n",
    "    texto = re.sub(r'[^\\w\\sáéíóúüñÁÉÍÓÚÜÑ.,;:!?]', '', texto)  # eliminar símbolos raros\n",
    "    texto = texto.replace(\"*\", \"\")\n",
    "    texto = re.sub(r\"([a-z])([A-Z])\", r\"\\1 \\2\", texto)\n",
    "    texto = texto.strip()\n",
    "    return texto\n",
    "\n",
    "texto_total_limpio = limpiar_texto(texto_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6t5m7X731s2f"
   },
   "source": [
    "### Segmentación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8R9MyHLm8PFR"
   },
   "source": [
    "Se separa el texto por saltos de línea dobles, lo que permite identificar bloques temáticamente coherentes.\n",
    "\n",
    "Luego, se aplica una segmentación \"consciente del contenido\" que conserva la estructura semántica de manera eficiente y mantiene el contexto.\n",
    "\n",
    "Finalmente, se agrupan las oraciones para evitar fragmentos demasiado cortos o ambiguos, lo cual mejora la calidad de los embeddings generados por modelos como S-BERT.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "6GZVdfx6o9To",
    "outputId": "95fea9b3-3fce-4296-ded1-68595655e33a"
   },
   "outputs": [],
   "source": [
    "!python -m spacy download es_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fm8PxydC1YxO"
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# Cargar modelo de spaCy para español\n",
    "nlp = spacy.load(\"es_core_news_sm\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W9k-N0fr1toV",
    "outputId": "47b32626-d312-4c9f-fa25-2caa3413b6a5"
   },
   "outputs": [],
   "source": [
    "fragmentos = []\n",
    "for bloque in re.split(r'(?:\\n\\s*){2,}', texto_total):  #  esto detecta bloques separados por líneas vacías\n",
    "    doc = nlp(bloque.strip())\n",
    "    oraciones = [sent.text.strip() for sent in doc.sents if len(sent.text.strip()) > 10]\n",
    "\n",
    "    # Agrupar de a 2 oraciones\n",
    "    temp = []\n",
    "    for i, oracion in enumerate(oraciones):\n",
    "        temp.append(oracion)\n",
    "        if len(temp) == 2 or i == len(oraciones) - 1:\n",
    "            fragmentos.append(\" \".join(temp))\n",
    "            temp = []\n",
    "# Ver algunos ejemplos\n",
    "for i, frag in enumerate(fragmentos[:5]):\n",
    "    print(f\"Fragmento {i+1}:\\n{frag}\\n{'-'*40}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UJ9OeRXWzAqB",
    "outputId": "ad89e830-54d4-4a6b-bf01-14daf4c2c0f6"
   },
   "outputs": [],
   "source": [
    "# Se comprueba la cantidad de tokens que tienen los fragmentos\n",
    "\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Cargar el modelo\n",
    "modelo = SentenceTransformer(\"distiluse-base-multilingual-cased-v1\")\n",
    "tokenizer = modelo.tokenizer\n",
    "\n",
    "# Contar tokens de cada fragmento\n",
    "token_counts = [len(tokenizer(frag)[\"input_ids\"]) for frag in fragmentos]\n",
    "\n",
    "# Crear DataFrame\n",
    "df = pd.DataFrame({\n",
    "    \"Fragmento\": fragmentos,\n",
    "    \"N_Tokens\": token_counts\n",
    "})\n",
    "\n",
    "bins = [0, 10, 20, 30, 40, 50, 60, 80, 100, 128, float(\"inf\")]\n",
    "labels = [\n",
    "    \"0–10\", \"11–20\", \"21–30\", \"31–40\", \"41–50\",\n",
    "    \"51–60\", \"61–80\", \"81–100\", \"101–128\", \"129+\"\n",
    "]\n",
    "\n",
    "# Asignar fragmentos a rangos de tokens\n",
    "df[\"Rango_Tokens\"] = pd.cut(df[\"N_Tokens\"], bins=bins, labels=labels, right=True)\n",
    "\n",
    "# Calcular frecuencia por rango\n",
    "frecuencia = df[\"Rango_Tokens\"].value_counts().sort_index()\n",
    "\n",
    "# tabla de frecuencias\n",
    "tabla_frecuencia = frecuencia.reset_index()\n",
    "tabla_frecuencia.columns = [\"Rango de Tokens\", \"Cantidad de Fragmentos\"]\n",
    "print(tabla_frecuencia)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nlSccxiTFWbk"
   },
   "source": [
    "### Vectorización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ggysCeBN4Sxs"
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "from prettytable import PrettyTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "iZt3SFUg4AYX"
   },
   "outputs": [],
   "source": [
    "# Cargamos el modelo preentrenado multilingüe\n",
    "modelo = SentenceTransformer(\"distiluse-base-multilingual-cased-v1\")\n",
    "# Codificamos los fragmentos\n",
    "embeddings = modelo.encode(fragmentos, convert_to_tensor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d145dPlT4p5j",
    "outputId": "04fb220c-1458-4012-d135-aa63dbd6749c"
   },
   "outputs": [],
   "source": [
    "# Calculamos las puntuaciones de similitud\n",
    "puntuaciones_coseno = util.cos_sim(embeddings, embeddings)\n",
    "\n",
    "# Encontramos las puntuaciones de similitud más altas\n",
    "pares = []\n",
    "for i in range(len(puntuaciones_coseno)-1):\n",
    "    for j in range(i+1, len(puntuaciones_coseno)):\n",
    "        pares.append({'index': [i, j], 'score': puntuaciones_coseno[i][j]})\n",
    "\n",
    "# Ordenamos las puntuaciones en orden decreciente\n",
    "pares = sorted(pares, key=lambda x: x['score'], reverse=True)\n",
    "\n",
    "# Creamos una tabla para mostrar los resultados\n",
    "tabla = PrettyTable()\n",
    "tabla.field_names = [\"Oración 1\", \"Oración 2\", \"Puntuación de Similitud\"]\n",
    "\n",
    "# Añadimos las filas a la tabla\n",
    "for par in pares[0:10]:\n",
    "    i, j = par['index']\n",
    "    tabla.add_row([fragmentos[i], fragmentos[j], f\"{par['score']:.4f}\"])\n",
    "\n",
    "\n",
    "print(tabla)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UOCmN_ZqGwtl"
   },
   "source": [
    "### Análisis de similitud de texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7mfrYK1y6goK",
    "outputId": "68013020-1d60-4c9b-ca52-5f2aa04b79dd"
   },
   "outputs": [],
   "source": [
    "consultas = [\n",
    "    \"es un juego que tine un\",\n",
    "    \"cuando se termina el juego\",\n",
    "    \"reseña y opiniones del juego\",\n",
    "    \"como se desarrolla una partida\"\n",
    "]\n",
    "\n",
    "consulta_embeddings = modelo.encode(consultas, convert_to_tensor=True)\n",
    "\n",
    "# Calcular similitudes coseno\n",
    "resultados = util.cos_sim(consulta_embeddings, embeddings)\n",
    "\n",
    "# Mostrar los fragmentos más similares por cada consulta\n",
    "top_k = 2\n",
    "for i, consulta in enumerate(consultas):\n",
    "    print(f\"\\n🔍 Consulta: {consulta}\")\n",
    "    valores_sim, idxs = resultados[i].topk(top_k)\n",
    "    for score, idx in zip(valores_sim, idxs):\n",
    "        print(f\"\\n* Similitud: {score.item():.4f}\")\n",
    "        print(f\"{fragmentos[idx]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_j6ube6SHr0f"
   },
   "source": [
    "### Métricas de Semejanza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "kq0DL-m4yy5N",
    "outputId": "2282de81-c07a-4b9f-ff89-575cdef4c15d"
   },
   "outputs": [],
   "source": [
    "!pip install python-Levenshtein jellyfish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PMgiASmTYa1L"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.spatial.distance import jaccard\n",
    "from Levenshtein import distance as levenshtein_distance\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import jellyfish\n",
    "\n",
    "def dice_similarity(s1, s2):\n",
    "    set1, set2 = set(s1.split()), set(s2.split())\n",
    "    if not set1 or not set2:\n",
    "        return 0.0\n",
    "    return 2 * len(set1 & set2) / (len(set1) + len(set2))\n",
    "\n",
    "def buscar_similares(frase_consulta, top_k=3):\n",
    "    print(f\"\\n🔍 Frase de búsqueda: {frase_consulta}\")\n",
    "\n",
    "    # Vector S-BERT de la consulta\n",
    "    vector_consulta = modelo.encode([frase_consulta], convert_to_tensor=True)\n",
    "\n",
    "    # ---------- MÉTRICA 1: Coseno ----------\n",
    "    similitudes_coseno = cosine_similarity(vector_consulta, embeddings)[0]\n",
    "    top_coseno_idx = np.argsort(similitudes_coseno)[-top_k:][::-1]\n",
    "\n",
    "    print(\"\\n📐 Resultados por *Similitud del coseno*:\")\n",
    "    for idx in top_coseno_idx:\n",
    "        print(f\"  ({similitudes_coseno[idx]:.3f}) {fragmentos[idx][:100]}...\")\n",
    "\n",
    "    # ---------- MÉTRICA 2: Jaccard ----------\n",
    "    vectorizer = CountVectorizer(binary=True)\n",
    "    binarized = vectorizer.fit_transform([frase_consulta] + fragmentos)\n",
    "    jaccard_scores = [\n",
    "        1 - jaccard(binarized[0].toarray()[0], binarized[i+1].toarray()[0])\n",
    "        for i in range(len(fragmentos))\n",
    "    ]\n",
    "    top_jaccard_idx = np.argsort(jaccard_scores)[-top_k:][::-1]\n",
    "\n",
    "    print(\"\\n📐 Resultados por *Distancia de Jaccard*:\")\n",
    "    for idx in top_jaccard_idx:\n",
    "        print(f\"  ({jaccard_scores[idx]:.3f}) {fragmentos[idx][:100]}...\")\n",
    "\n",
    "    # ---------- MÉTRICA 3: Dice ----------\n",
    "    dice_scores = [dice_similarity(frase_consulta, frag) for frag in fragmentos]\n",
    "    top_dice_idx = np.argsort(dice_scores)[-top_k:][::-1]\n",
    "\n",
    "    print(\"\\n📐 Resultados por *Similitud de Dice*:\")\n",
    "    for idx in top_dice_idx:\n",
    "        print(f\"  ({dice_scores[idx]:.3f}) {fragmentos[idx][:100]}...\")\n",
    "\n",
    "\n",
    "    return vector_consulta, top_coseno_idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KAx2Apj0z9g2",
    "outputId": "5d394798-de5c-44c1-e0dd-d80877a8fcd5"
   },
   "outputs": [],
   "source": [
    "vector_consulta, top_coseno_idx = buscar_similares(\"cuando o como finaliza el juego para un los participantes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G__dpKob-jL_"
   },
   "source": [
    "Para realizar la búsqueda semántica entre fragmentos de texto, probamos distintas métricas de Semejanza:\n",
    "\n",
    "**Similitud del coseno**, que utiliza vectores densos de embeddings para capturar significado más allá de palabras literales.\n",
    "\n",
    "**Distancia de Jaccard** y **Similitud de Dice**, que comparan palabras presentes en los textos en forma binaria.\n",
    "\n",
    "Otras métricas como Levenshtein o Jaro-Winkler se descartaron porque miden diferencias a nivel de caracteres y no son adecuadas para evaluar similitud semántica entre textos largos o fragmentados.\n",
    "\n",
    "**La Similitud del coseno fue la que mejor reflejó la relación semántica entre la consulta y los fragmentos, por lo que se eligió como métrica principal para el análisis.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dax0ul5pIfOx"
   },
   "source": [
    "### Visualización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M5Ij5xwvPDNv"
   },
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "def visualizar_tsne_3D(embeddings, vector_consulta, fragmentos, top_idx=None):\n",
    "    import numpy as np\n",
    "\n",
    "    # Unir embeddings + consulta\n",
    "    all_vectors = np.vstack([vector_consulta, embeddings])\n",
    "\n",
    "    # Aplicar t-SNE\n",
    "    tsne = TSNE(n_components=3, perplexity=30, n_iter=1000, random_state=42, init='pca')\n",
    "    emb_3d = tsne.fit_transform(all_vectors)\n",
    "\n",
    "    # Separar los puntos\n",
    "    consulta_3d = emb_3d[0]\n",
    "    frag_3d = emb_3d[1:]\n",
    "\n",
    "    # Graficar\n",
    "    fig = plt.figure(figsize=(10, 7))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "    # Fragmentos\n",
    "    ax.scatter(frag_3d[:, 0], frag_3d[:, 1], frag_3d[:, 2], alpha=0.6, label='Fragmentos')\n",
    "\n",
    "    # Consulta\n",
    "    ax.scatter(consulta_3d[0], consulta_3d[1], consulta_3d[2], c='red', s=100, label='Frase de búsqueda')\n",
    "\n",
    "    # Más similares\n",
    "    if top_idx is not None and len(top_idx) > 0:\n",
    "        ax.scatter(frag_3d[top_idx, 0], frag_3d[top_idx, 1], frag_3d[top_idx, 2],\n",
    "                   c='green', s=60, label='Más similares')\n",
    "\n",
    "    ax.set_title(\"Visualización 3D con t-SNE\")\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "\n",
    "    return emb_3d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 653
    },
    "id": "0FU2kcVpPD9d",
    "outputId": "0ee43ca0-3135-4266-a493-e0678ff81325"
   },
   "outputs": [],
   "source": [
    "emb_3d_tsne = visualizar_tsne_3D(\n",
    "    embeddings=embeddings,\n",
    "    vector_consulta=vector_consulta,\n",
    "    fragmentos=fragmentos,\n",
    "    top_idx=top_coseno_idx  # o top_jaccard_idx, etc.\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C5hOv_maLTiS"
   },
   "source": [
    "## EJERCICIO 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0IAtzv45F3zs"
   },
   "source": [
    "### Cargamos el texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uGVsIb3YLTiT",
    "outputId": "3d52adc5-9a2a-4ebe-de02-9c312214cd92"
   },
   "outputs": [],
   "source": [
    "#cargamos el texto\n",
    "ruta = \"/content/NLP_TP1/datos/informacion/manual.txt\"\n",
    "\n",
    "with open(ruta, \"r\", encoding=\"utf-8\") as file:\n",
    "    texto_manual = file.read()\n",
    "\n",
    "# Análisis básico\n",
    "num_caracteres = len(texto_manual)\n",
    "num_palabras = len(texto_manual.split())\n",
    "\n",
    "print(f\" El texto contiene {num_caracteres} caracteres y {num_palabras} palabras.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xHhrL11BLTiU"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Limpieza mínima\n",
    "texto_manual_limpio = re.sub(r'\\s+', ' ', texto_manual).strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pgdWSsBsF-kW"
   },
   "source": [
    "### Segmentación con spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "Xnx8IVJ-sal4",
    "outputId": "e8d784ea-bf26-4ff2-f0d2-115c7a1720c7"
   },
   "outputs": [],
   "source": [
    "!python -m spacy download en_core_web_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xIfNK3HZsVve"
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "# spaCy en inglés\n",
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0xveLakYrzHg"
   },
   "outputs": [],
   "source": [
    "# Segmentación del texto\n",
    "doc_total = nlp(texto_manual_limpio)\n",
    "fragmentos = [sent.text.strip() for sent in doc_total.sents]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jGnc1t6pGHg8"
   },
   "source": [
    "### POS y NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "KBhIByBjL60l",
    "outputId": "b2252ade-16a0-468c-ea00-20ccc1dbd35d"
   },
   "outputs": [],
   "source": [
    "!pip install spacy gliner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "812f4c758b184b8bb8abdede9f64f5f3",
      "0f565fb4b6df460d9738c3917e2caadc",
      "4f5959514974417abd177f534676f4a5",
      "4c4e45a4cfea4c63a809da6b6e884d00",
      "0f584c2069034d54a9418c15263ea0c8",
      "b622b13c47cd48b59d6f7732130f82c3",
      "38f92b3a35a543299a616c32a2f1fdad",
      "ab959952fee843628254416cfee9a102",
      "69ef55f4e74746d1aa131548d71c562f",
      "ee11fb1192a0490d910b16115eb70495",
      "39b4f60dff4745a89e25261cb6146d56",
      "68159a3520d545509c6ae09404ae3f20",
      "947c0686d9434d34bd70ddb52d46c12f",
      "3992b8ff804542a1b2ea5b5f853d4f43",
      "f96aec393950420e89a88bab650b6c93",
      "fec13fa614c24ab5b75ef0255e49926c",
      "960dd8e35e644038b3b68175a8d3a86f",
      "261f3377716c4a71833e60ff3baebaab",
      "3632321a45d049009de775675aabd4b2",
      "7f7b0fbfc70d4d808367bad39d8735f9",
      "fcecd4977a9348a099139682c4da0944",
      "477e9ba355114edcb87313b20e4aeacd",
      "03b00a9ba90c47fb999da65aed355f5c",
      "c1831c0d7a084acba74fb42852561c86",
      "c23cecd42b5d4ea48640e3362939b0aa",
      "7d61badccdbf4a4aa6d8b13eca08778d",
      "4a67d44e59a1429e94281229f7ac7859",
      "4fe04329d0b84b7c8f4b597c4cce45d5",
      "098a2b470be94dec8688929bb316856c",
      "c7d47d62daad4ffb8234df3d6c15e6be",
      "e4298b42331145c5aacf2a387439969a",
      "4046e219970d43299c9b21b68c0098f3",
      "632f656e1c6b4a2399b3a9f85bc0d5f1",
      "796cebc39fb044228df434055efbc829",
      "f1351e8b8927415295da08152a1fa96b",
      "4cecea9eecde4fe0a3cb363a3aeb09e9",
      "d58369e141c5455d9e0e489aed01df52",
      "cf1779128212435784d6161222bcfe44",
      "776b2233e17449bcbe047bc69c88f9a6",
      "d396657d0e2f423cbcab1e37c727d4b2",
      "b2a6c131f7ba417eaccc54c05b106900",
      "cade3f9597fe4479b867f244879952fb",
      "67937c8ff9df41b59a6866cdbd78b33c",
      "c0626dc13c9e4435bb3232bc2b137ed8",
      "9aaabeed93ab4e549b92ed94c7a69f4d",
      "0f29377c90684f819c8aa8264f20407a",
      "6f3d2ae5f36c41f6aa859ca78b71ecf0",
      "bd5db73b63914891b61b8dc9500893bd",
      "630cdce453f04371b297491fd47208c8",
      "2e6b15fdb2f2492f92faef90343f28c1",
      "448723d0a55b4dc2ade2d53f58656f4c",
      "f8ee261726d349d4b5e91a1ef39b89e1",
      "355fc8bb4b884885b233cb388ee30d67",
      "8d2dd4ca90504bd6b2955d507e5ae0af",
      "a7e86350f0ee4d03b45ad961b4fa1d64",
      "65413bb867d84709a1f94cbbc229aead",
      "26da2620b4584c04b9278aa3a668a57c",
      "5320d38147a3437587219cd795fcbf1b",
      "75254230daac4af3ba0eefd1d5091065",
      "c5fa6e11b31742c48db042a6a83506c0",
      "d8f23f3f236849b8a0a052bc74943553",
      "15fc5e2ecc86494bbe913109003587c9",
      "dc432ff2358b43538b07ccdae6421e24",
      "b776d6d56e05447c80c7ed7ebdf9e3c7",
      "93090c620584496a906a65fea44468c1",
      "30c3c87719304a4db962b5ed75bf7412",
      "7c88df7b5a054996b6bccc373b8c9a58",
      "819e6953d6304dfe96c1e42a9a22d478",
      "cea3a1e8d78f4bc685926685a7daeddd",
      "fd5551bdee8845bdb17a027e66433c88",
      "b2f8c611729047208c1081c9401ce946",
      "9105387cb1c448daa4f25ad7d1e80bc9",
      "8131c33e29014f448f118a871fdfeebf",
      "4207d293145544d6bb176d2450065ff8",
      "4b2707e6ddfd456186b71be11b4bd6e4",
      "d2ae7d8c86234196a7c73cca12df4cf7",
      "e8e49974efd5465c8145f0b3dbd6c73c",
      "91b211aa9ec94695aa51788448dbb6a7",
      "115420ca04344f54ba76285ebf666b56",
      "a49ce546355b4767ae35611b40740076",
      "2771542bd3b74b059f6130c62a295bf8",
      "cd6ec15f30dd421b854c58bd26ecf8bf",
      "253b04887ecf4d3faac56d1b70b2ed7d",
      "4053458e6b15478b98d6aac079947495",
      "a3cd235f85bd4cc4adb640e39a563dab",
      "9a9a5a1c7cff41b3b22f86bc4dbace8c",
      "eb76bcfa1d13450e867d68c6da1453a0",
      "82244aaacb934220a04c60bc9013ec87"
     ]
    },
    "collapsed": true,
    "id": "q7c9IHaSrK1c",
    "outputId": "86ebe5fc-e37f-46c3-bff9-b8e29ebee666"
   },
   "outputs": [],
   "source": [
    "from gliner import GLiNER\n",
    "\n",
    "# GLiNER multilingüe\n",
    "gliner = GLiNER.from_pretrained(\"urchade/gliner_multi-v2.1\")\n",
    "gliner.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hz3LtUT_tpip",
    "outputId": "b68891b9-f48e-4ee0-c035-2cadb275407c"
   },
   "outputs": [],
   "source": [
    "sustantivos_por_fragmento = []\n",
    "entidades_por_fragmento = []\n",
    "\n",
    "for i, frag in enumerate(fragmentos):\n",
    "\n",
    "    # spaCy: extraer sustantivos\n",
    "    doc_frag = nlp(frag)\n",
    "    nouns = [token.text for token in doc_frag if token.pos_ in {\"NOUN\", \"PROPN\"}]\n",
    "    sustantivos_por_fragmento.append(nouns)\n",
    "    print(\"Sustantivos detectados (POS):\", nouns)\n",
    "\n",
    "    # GLiNER: entidades personalizadas\n",
    "    labels = [\"person\", \"book\", \"location\", \"date\", \"character\", \"board game\", \"GameComponent\",\n",
    "              \"ResourceType\",\"BuildingType\",\"Role\", \"RuleName\"]\n",
    "    ents = gliner.predict_entities(frag, labels, threshold=0.4)\n",
    "    entidades_por_fragmento.append(ents)\n",
    "\n",
    "    for ent in ents:\n",
    "        print(f\" - {ent['text']} => {ent['label']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T71O1C68Oxen"
   },
   "outputs": [],
   "source": [
    "sustantivos_ner = []\n",
    "\n",
    "for ents in entidades_por_fragmento:\n",
    "    # Extraer solo el texto de las entidades (que son los sustantivos o nombres detectados por NER)\n",
    "    sustantivos_ner.append([ent[\"text\"] for ent in ents])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AGkmWIOja_6J",
    "outputId": "c200235f-7421-41e6-b6e4-a47dff3f86f0"
   },
   "outputs": [],
   "source": [
    "print(sustantivos_ner)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "djlx0SDdmGTE"
   },
   "source": [
    "### Búsqueda de similitud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cOoYcGPrGV-I"
   },
   "source": [
    "#### Vectorización con FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "rhIx5cgbFkPq",
    "outputId": "1c8baab7-d5a9-4822-8b90-37506be6b1a6"
   },
   "outputs": [],
   "source": [
    "!pip install fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A5-MTuvQEfJc",
    "outputId": "0687eb4d-5f0e-4392-9fc7-4c0cd24670b9"
   },
   "outputs": [],
   "source": [
    "import fasttext\n",
    "import fasttext.util\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Descargar modelo en inglés\n",
    "fasttext.util.download_model('en', if_exists='ignore')\n",
    "ft_model = fasttext.load_model('cc.en.300.bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0nsN-b1OgkVx"
   },
   "source": [
    "#### Métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HareUoiFggEj"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import Levenshtein\n",
    "import jellyfish\n",
    "from sklearn.metrics.pairwise import cosine_similarity as sk_cosine_similarity\n",
    "\n",
    "# --- Funciones métricas ---\n",
    "\n",
    "def cosine_similarity(vec1, vec2):\n",
    "    if np.linalg.norm(vec1) == 0 or np.linalg.norm(vec2) == 0:\n",
    "        return 0.0\n",
    "    return np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))\n",
    "\n",
    "def jaccard_distance(str1, str2):\n",
    "    set1, set2 = set(str1), set(str2)\n",
    "    inter = set1.intersection(set2)\n",
    "    union = set1.union(set2)\n",
    "    return 1 - len(inter) / len(union) if union else 1.0\n",
    "\n",
    "def dice_similarity(str1, str2):\n",
    "\n",
    "    def bigrams(s):\n",
    "        return set([s[i:i+2] for i in range(len(s)-1)]) if len(s) > 1 else set()\n",
    "    bigr1 = bigrams(str1)\n",
    "    bigr2 = bigrams(str2)\n",
    "    inter = bigr1.intersection(bigr2)\n",
    "    return 2 * len(inter) / (len(bigr1) + len(bigr2)) if (len(bigr1)+len(bigr2)) > 0 else 0.0\n",
    "\n",
    "def levenshtein_distance(str1, str2):\n",
    "    return Levenshtein.distance(str1, str2)\n",
    "\n",
    "def jaro_winkler_similarity(str1, str2):\n",
    "    return jellyfish.jaro_winkler_similarity(str1, str2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JwlvCLn5gsms"
   },
   "source": [
    "#### Funciones de busqueda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "01iwurDBQ3ld"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Aplanar la lista de listas de sustantivos filtrados por NER y pasar a minúsculas\n",
    "sustantivos_filtrados = [noun.lower() for sublist in sustantivos_ner for noun in sublist]\n",
    "\n",
    "# Quitar duplicados\n",
    "sustantivos_unicos = list(set(sustantivos_filtrados))\n",
    "\n",
    "\n",
    "# --- Funciones de búsqueda por cada métrica ---\n",
    "\n",
    "def buscar_por_coseno(query, lista, ft_model, top_k=3):\n",
    "    query_vec = ft_model.get_word_vector(query.lower())\n",
    "    similitudes = []\n",
    "    for palabra in lista:\n",
    "        vec = ft_model.get_word_vector(palabra)\n",
    "        sim = cosine_similarity(query_vec, vec)\n",
    "        similitudes.append((palabra, sim))\n",
    "    similitudes = sorted(similitudes, key=lambda x: x[1], reverse=True)\n",
    "    return similitudes[:top_k]\n",
    "\n",
    "def buscar_por_jaccard(query, lista, top_k=3):\n",
    "    distancias = []\n",
    "    for palabra in lista:\n",
    "        dist = jaccard_distance(query.lower(), palabra)\n",
    "        distancias.append((palabra, dist))\n",
    "    distancias = sorted(distancias, key=lambda x: x[1])\n",
    "    return distancias[:top_k]\n",
    "\n",
    "def buscar_por_levenshtein(query, lista, top_k=3):\n",
    "    distancias = []\n",
    "    for palabra in lista:\n",
    "        dist = levenshtein_distance(query.lower(), palabra)\n",
    "        distancias.append((palabra, dist))\n",
    "    distancias = sorted(distancias, key=lambda x: x[1])\n",
    "    return distancias[:top_k]\n",
    "\n",
    "def buscar_por_dice(query, lista, top_k=3):\n",
    "    similitudes = []\n",
    "    for palabra in lista:\n",
    "        sim = dice_similarity(query.lower(), palabra)\n",
    "        similitudes.append((palabra, sim))\n",
    "    similitudes = sorted(similitudes, key=lambda x: x[1], reverse=True)\n",
    "    return similitudes[:top_k]\n",
    "\n",
    "def buscar_por_jaro_winkler(query, lista, top_k=3):\n",
    "    similitudes = []\n",
    "    for palabra in lista:\n",
    "        sim = jaro_winkler_similarity(query.lower(), palabra)\n",
    "        similitudes.append((palabra, sim))\n",
    "    similitudes = sorted(similitudes, key=lambda x: x[1], reverse=True)\n",
    "    return similitudes[:top_k]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l3MTvl4OjEnE"
   },
   "source": [
    "#### Busqueda de Similitud con distancias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vH7VM5Wwj-8A"
   },
   "source": [
    "Para una “similitud textual” (si se parecen las palabras de forma escrita) las métricas como Jaccard, Levenshtein, Dice, Jaro-Winkler son adecuadas porque miden la similitud basada en caracteres o tokens. Entre estas métricas, Jaro-Winkler suele ser la más efectiva porque pondera los prefijos comunes y corrige bien errores de tipeo al inicio de las palabras,.\n",
    "\n",
    "Pero si pensamos en “similitud semántica” (relación de significado o contexto) similitud por coseno es la mejor opción."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0C5f3DODg7dW"
   },
   "outputs": [],
   "source": [
    "# Función general que muestra todo\n",
    "def buscar_similitudes(query, palabras, ft_model, top_k=3):\n",
    "    print(f\"\\nSimilitud coseno con FastText para '{query}':\")\n",
    "    for palabra, score in buscar_por_coseno(query, palabras, ft_model, top_k):\n",
    "        print(f\"  {palabra}: {score:.3f}\")\n",
    "\n",
    "    print(f\"\\nSimilitud de Jaccard para '{query}':\")\n",
    "    for palabra, score in buscar_por_jaccard(query, palabras, top_k):\n",
    "        print(f\"  {palabra}: {score:.3f}\")\n",
    "\n",
    "    print(f\"\\nSimilitud de Levenshtein para '{query}':\")\n",
    "    for palabra, score in buscar_por_levenshtein(query, palabras, top_k):\n",
    "        print(f\"  {palabra}: {score:.3f}\")\n",
    "\n",
    "    print(f\"\\nSimilitud de Dice para '{query}':\")\n",
    "    for palabra, score in buscar_por_dice(query, palabras, top_k):\n",
    "        print(f\"  {palabra}: {score:.3f}\")\n",
    "\n",
    "    print(f\"\\nSimilitud de Jaro-Winkler para '{query}':\")\n",
    "    for palabra, score in buscar_por_jaro_winkler(query, palabras, top_k):\n",
    "        print(f\"  {palabra}: {score:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tJEmiduWhT6-",
    "outputId": "4ae49d03-fb84-41ad-b31e-c562ae7ef449"
   },
   "outputs": [],
   "source": [
    "buscar_similitudes(\"Fyni tonw\", sustantivos_unicos, ft_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "48eatprhi1vI",
    "outputId": "53da03c1-4544-46e4-d80a-5a0ac5e111b7"
   },
   "outputs": [],
   "source": [
    "buscar_similitudes(\"Construct\", sustantivos_unicos, ft_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bOU3TTiAoCsc"
   },
   "source": [
    "## EJERCICIO 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "IICUDvEUoaAB",
    "outputId": "59a53a22-1b6d-4f10-fdb4-d91372d018db"
   },
   "outputs": [],
   "source": [
    "!pip install langdetect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AT8xgv5soMHw",
    "outputId": "05332542-fb26-48ec-cd16-82119d6f5672"
   },
   "outputs": [],
   "source": [
    "from langdetect import detect, DetectorFactory\n",
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "\n",
    "DetectorFactory.seed = 0\n",
    "\n",
    "# Carpeta raíz donde están las carpetas 'estadisticas', 'informacion', 'relaciones'\n",
    "root_dir = '/content/NLP_TP1/datos'\n",
    "\n",
    "resultados = []\n",
    "\n",
    "for carpeta, subcarpetas, archivos in os.walk(root_dir):\n",
    "    for archivo in archivos:\n",
    "        ruta = os.path.join(carpeta, archivo)\n",
    "\n",
    "        if archivo.endswith(('.txt', '.csv')):\n",
    "            try:\n",
    "                with open(ruta, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "                    texto = f.read()\n",
    "                if texto.strip():\n",
    "                    idioma = detect(texto)\n",
    "                else:\n",
    "                    idioma = 'vacío'\n",
    "                resultados.append({'archivo': ruta, 'idioma': idioma})\n",
    "            except Exception as e:\n",
    "                print(f\"Error leyendo {ruta}: {e}\")\n",
    "\n",
    "# Creamos el DataFrame con resultados\n",
    "df_idiomas = pd.DataFrame(resultados)\n",
    "\n",
    "print(df_idiomas)\n",
    "\n",
    "# Copiamos los archivos en carpetas separadas según el idioma\n",
    "carpeta_destino = '/content/NLP_TP1/datos_separados'\n",
    "\n",
    "os.makedirs(carpeta_destino, exist_ok=True)\n",
    "\n",
    "for _, fila in df_idiomas.iterrows():\n",
    "    archivo = fila['archivo']\n",
    "    idioma = fila['idioma']\n",
    "\n",
    "    carpeta_idioma = os.path.join(carpeta_destino, idioma)\n",
    "    os.makedirs(carpeta_idioma, exist_ok=True)\n",
    "\n",
    "    nombre_archivo = os.path.basename(archivo)\n",
    "    destino = os.path.join(carpeta_idioma, nombre_archivo)\n",
    "\n",
    "    shutil.copy2(archivo, destino)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4k4uwNY_r6JL"
   },
   "source": [
    "## EJERCICIO 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aK9Icf_AteaQ"
   },
   "source": [
    "### Análisis de sentimientos (BERT multilingüe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZArC_OMkr8sJ"
   },
   "outputs": [],
   "source": [
    "# Reemplazá con el nombre correcto de tu archivo\n",
    "df = pd.read_csv(\"/content/NLP_TP1/datos/informacion/df_foros_bgg.csv\")\n",
    "\n",
    "# Nos quedamos solo con las Reviews\n",
    "reviews_df = df[df[\"Category\"] == \"Reviews\"].copy()\n",
    "reviews_df.dropna(subset=[\"Conversation\"], inplace=True)\n",
    "reviews_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 194,
     "referenced_widgets": [
      "4503365125b946aea036a2fdc3bedade",
      "c2a669bf0ef34b559c6e8d3260f895b7",
      "89f73186cba64cf394ac0c93a082dea3",
      "df8f9278ba434a5daf14086ac3ac0469",
      "a9922e7f4ef643ff89fa76c60b8a3bf2",
      "339fc1a6802a4fab99e3279f8e7862d8",
      "76d46a6dbf5e4b6887db9be22b9fdf62",
      "88fd6670d14f42bca019a1414f73e904",
      "9a2ceeffdf8a4271b18ef2ff0dcd5d57",
      "058e1f71d42c44de853507375c81a7da",
      "ad75a93e6eb34f4f9258237119a8a13f",
      "f5583beb320b45388ba6b52e9ee1b521",
      "4ab3c96816454bf8bc665041b0555e2b",
      "55b708e530cc47fc81e5a47f1a82c88a",
      "62e5d1a6e43149b79a2f35f51d81cd8a",
      "03b95d94380e40df9d4b4bdb8449481e",
      "9711366791c545d28923be6b5e3347c4",
      "b8cb96092b2a4f13b225dd58960d03bf",
      "8106b6a62eb7429da15fdfc1e4162a27",
      "a53f58090a074ad4a38b5767ce51619b",
      "65f94588979b45fda183f5451dd94e00",
      "c6eadd4367c5451cbb84d7b6dea5b261",
      "97bb78589b2d4367a28401b14fb26db8",
      "07661b8434384636b0e3eed3ea958d36",
      "96ce4523443d49108cec37e3e3ecc172",
      "101a37ef2fdf41c0a8d0de172c755ce6",
      "72872ca55680467b99d54b21dc206d4b",
      "57dcc33ca39246d28bcfdc09539f8434",
      "f9719f4f23294a74a2a381341ed4fd40",
      "d730da29c0ee4bf8a9fe2f7e2e439939",
      "ac9a7bbd36c54f089cddec3bc2d977e5",
      "e53ed39fc74d4614adea12dfc7b9364d",
      "ffa1887f3c2e400ab3a46a210314f2a7",
      "00e162f0a94a4bf48d624bb0cb4acc92",
      "26b1421f388f4e959d5e33ed1ecc06e8",
      "2f7b3b537fce4a608f4e4fd2f53636be",
      "88ecd4b408444cd99a58e8be576d8b6c",
      "ea449c51ad644bc7a7976649d499145c",
      "f74e1ddc99474f7d90e2cf7fbdcce5a2",
      "ad9419e2b2f64fc1a8facac7d9429dd5",
      "a4edc992dfcb4c3faaf5bfd8902b87de",
      "e67d1ea581f24668bbb274d9686266eb",
      "e23aabd9c54143a8b2a607354c9bde78",
      "5579aabdb6c24aeea40a056cbadc1589",
      "63766e72eb7f40f08e9802e00e5011ad",
      "f38a3b20cdea40dc933f041c873d6bc1",
      "5fb8e5cf5b374c738208d931d526543d",
      "b50692cac63f47b291df9395f4475b0e",
      "5a5a21f278744bc79b4b9ceca04288e4",
      "ac7ecdaee5aa42ac96718168d68c257a",
      "f627f713715648229cd8ce52774c5fce",
      "4ebe5dbd2ccc43f2ac709f1755170bae",
      "b7c1ac2d1c3e4f35854738434b9fb12f",
      "36b5668b01124c2c9127977fcfd89658",
      "0010d2098e8e469d8c4978aae59cac56"
     ]
    },
    "collapsed": true,
    "id": "RHoSPCU1sKLU",
    "outputId": "41e9be2c-6a3a-426b-fead-0db15161a4a2"
   },
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification, pipeline\n",
    "\n",
    "# Modelo entrenado en varios idiomas\n",
    "model_name = \"nlptown/bert-base-multilingual-uncased-sentiment\"\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "# Pipeline de análisis de sentimientos\n",
    "nlp = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "# Función para convertir estrellas a polaridad\n",
    "def stars_to_label(label):\n",
    "    stars = int(label.split()[0])\n",
    "    if stars <= 2:\n",
    "        return \"NEGATIVE\"\n",
    "    elif stars == 3:\n",
    "        return \"NEUTRAL\"\n",
    "    else:\n",
    "        return \"POSITIVE\"\n",
    "\n",
    "# Aplicar análisis a cada review\n",
    "reviews_df[\"Sentiment_raw\"] = reviews_df[\"Conversation\"].apply(lambda x: nlp(x[:512])[0])  # truncar a 512 tokens\n",
    "reviews_df[\"Sentiment\"] = reviews_df[\"Sentiment_raw\"].apply(lambda x: stars_to_label(x[\"label\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e7slGgvPtBAl"
   },
   "outputs": [],
   "source": [
    "reviews_df.to_csv(\"reviews_con_sentimientos.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "tpO2JRDDsj0g",
    "outputId": "1e7ec3ab-f809-4cce-e076-9e716124f14b"
   },
   "outputs": [],
   "source": [
    "reviews_df[[\"Conversation\", \"Sentiment_raw\", \"Sentiment\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4HZ_dhsFtkbD"
   },
   "source": [
    "### Sistema de búsqueda semántica + filtro por sentimiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424,
     "referenced_widgets": [
      "b1c789458e5f492ca82ab2f736e8aef1",
      "415c323f489845cdaeee86bb8087d22e",
      "5fcaa91c3a104f36a03a0182168b2312",
      "a82ca064f80645469b437172b99b4933",
      "4ad5b3e03432409a8c7cffcb7c02f955",
      "1551c81bd6674fe7b00bd51ef69e184c",
      "8954d0a0e8ae42e6af827751e7355a24",
      "0fe8ddb8c0e848079560b3f3e260dbdc",
      "6617d628aea2442ba43b9796258c5a14",
      "bdb2f8fa66a34a39bc208f31f88b2eb3",
      "6c97d2b421c746119d8a1eb2be9f7a57",
      "859503c7cff649c48165723b3dacd5e0",
      "01cc9719a60e4e37b2d56ed6c64f041b",
      "b9f97858c2f645b899c7f7e698fe477b",
      "4f38353c6f4a47fd950e7163e02dc2d8",
      "c607a8c665434a4bbd9055b7d47dc1f1",
      "8093ed32d166416dba85f9b58b146395",
      "8321e6a2d6bf42d48da3497e16f07a6b",
      "56e646124e164d75ac382e9db2c13b34",
      "0eb09a93dd8542eb9c122bd4594b1a09",
      "9899d4e5ecae49e18fee61057a0294dd",
      "9c5d13a300c24e8291e0e3044f8ba43d",
      "e54f2156d9b94e88b6890c0f6ffa4a9d",
      "80ab24347c884dc6ad88a2038df0aafd",
      "677d26e211814e3c8e64f11613cd2423",
      "0f3323149c2645e39849c4f6b17c81bc",
      "3365ce085a544edbbc61155fd2f2bd2f",
      "f1b5ce45347c48ebae09b04048510638",
      "71bf15b5bdb94d5b96402756fdadbad7",
      "1bc29105e7e9425498ddd9b991a0676a",
      "b7a3adf1cc1d45fa9b3690470db89d06",
      "4c3064d7b4c845f094e76f0c0d810d67",
      "360a2ece72e24b9cafdab13b4b9a73a3",
      "b183ee91f80d4caab1ba48528c119602",
      "36bd8ff523764d588472db6ba7dc22aa",
      "49f50b90e9584958b9c73770099754ce",
      "e4f101a6cdd049d78c53caab45daffa7",
      "109d09a4fd9440e48c05794909ed7244",
      "b873d45c8be04ed38cee9df08924e727",
      "b67e0fb6b0f44423a34a06613b824089",
      "4cc2f9d77f2243e9aea061e2cd6ead02",
      "10514131280844dab2a0a9d5b909ac03",
      "1243a79473a74f9daee5c97f3461435f",
      "cc1c579fd6e24e0f94e7f1c5d41336c4",
      "aefaf4bed2184a5c88a988d086a07858",
      "e7722c24b9284c53b96397914e735d19",
      "6f95dc57c2624c6ebab222ccb311d344",
      "0f3e065fcd6a4225b2620aa39429482b",
      "bc054cbcd7384e10a6c3f79a1e13a64b",
      "30299e98d1b04ca7a2cddf060da16013",
      "e9ec8bf255394ffe9cb62df62b2a79a3",
      "814a9e6935014a3bab2a180167f3f0a2",
      "b98f8f3420ba48f685041b1b4d3e3dc8",
      "e8ca5ab619cd4abd98f2799d423daadc",
      "1bcf88d8b1b740c586b977c79e3852e9",
      "07e9babd68fc43f6be8c461eb1bcc146",
      "db6812d698c147b98b6ff59e12995e44",
      "949bdcdd45764a53a0d9e948dce66a27",
      "94756aa356d64dbebf5e756b53667dc2",
      "a8d7f49127184f4f81bb5f14f4e09ae3",
      "c4ce570fad4143ca81b3d1ddc6d86b87",
      "7c845190ecd842cba458d7b0cb38285e",
      "a252c5fd7eed44d48d99ab25593118ad",
      "38eb7112d3684c01ab770f3690e33b33",
      "ba2549f9a34a4686a330b438e70e582f",
      "96031ca483dd44f7b2931ce10d911b22",
      "1636cdb8a46e419e845f7d7fc5ac6469",
      "4becdfa475814548b15cd12758b6461d",
      "089045e25866440384ac002c33cf1777",
      "857ba887dfdd4be38a9ee147085213f6",
      "c9d5d3828c4f44a2b449e45f8c96cc4e",
      "806d3f1e4e99490eac4aef1941d9d6dd",
      "9fc189bf98464e94b7d8f46f41065b6b",
      "09a7114cf45f4d9781bab428a85f98bb",
      "052a68c000414f529e7173c74c5e9de3",
      "753cfc1e990e425bb2c3772614e128d5",
      "812066089ad141809d4c9cad06492d5f",
      "aea7c54c456e41ebbaad3e1161ac06ba",
      "5c2b083493cc4814b3cf76f7a652cd4d",
      "c970385d7716461e960047d0e39a256b",
      "512b46eccfc64bacaea09f18eab9ddc8",
      "943fbbc3503747648a1854c764b2ee00",
      "0fed38496ec949ee9d662046d1846ede",
      "619d60315b104a17a8d13c551be1a45f",
      "7ee1fad10fd046ee8313a374bae75198",
      "094cf58c009945769123538ad4a58551",
      "078a2ab3d5b246558f90698313c7d4d9",
      "40119725db9940a0b6eb9ea52cb5354e",
      "15fa3fdb55aa46fbbb6cff619ca1f994",
      "6b878521bc1f4219b9122d9da8dcd162",
      "42a443cff0fd4aaa9c8c5fd45d188c6a",
      "9928118b0d744028a88224e5532d1238",
      "7aa1208ae12e4ffcb6366746b33f668b",
      "923c9982958943b8b8d7d92506298fcc",
      "0b0a8cd892cf4371862a51082ffe6834",
      "4bdbd59735ec4a5fa0f1d969c6ca55c8",
      "0a004049b79d426aad7a7a8aeddfa517",
      "819636097c934741adadea4010a44341",
      "61d82f3e800f4356869eca6eee22d759",
      "6691376945fa4745939858a10061d484",
      "a8e53329251443718ec8638183fde610",
      "ef567a64f1f54d30b801d8573c6c587c",
      "bd44a2a135064954b3733abe6b27266d",
      "19ca0d4efc52495583941d2c718f1091",
      "a99c542af627477dac6d895b81f25919",
      "f404f0c83bcd47c583ec789d2250c196",
      "7e468715233c459aa1b18d3564f3d4a4",
      "3d097039b26e4f7a8d7aecd25a035ad9",
      "d8ffbcff7b204b4f9d152d3b71106515",
      "63fae482415447a6b4dbf6db069f27b5",
      "036d30d1cdfd480ba328981c1aa26102",
      "3d8e67afb6354a80922607a35ead3eb9",
      "cfb0dd8272a048fca71b21abeda38988",
      "ad587d09a54740ab988a2278609aca42",
      "0aaad2622c51461683e9cb9c83f68d74",
      "aaf076331a07452b9aef38fb58ea75c0",
      "abd7968480be4c1d824a382e2ca19478",
      "ba2291e4e1964d049605e8af4012a767",
      "1939994109a84bef822433926a1c6d2a",
      "fd2a19e24682476096d47f85fd389c30",
      "9fb0f253ceba4dbfbcaa0708515ce3a2"
     ]
    },
    "collapsed": true,
    "id": "pCRP2my0tTEd",
    "outputId": "4eaf1d2c-c8e2-4567-841e-a120a1107e2e"
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Cargar modelo para embeddings\n",
    "embed_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Crear y almacenar los embeddings\n",
    "reviews_df[\"Embeddings\"] = embed_model.encode(reviews_df[\"Conversation\"].tolist()).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SyxoVnzbtuw0"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "def buscar_reviews(query, sentimiento=None, top_n=2):\n",
    "    # Obtener embedding del query\n",
    "    query_vec = embed_model.encode([query])\n",
    "\n",
    "    # Filtrar por sentimiento si se indica\n",
    "    if sentimiento:\n",
    "        df_filtrado = reviews_df[reviews_df[\"Sentiment\"] == sentimiento.upper()].copy()\n",
    "    else:\n",
    "        df_filtrado = reviews_df.copy()\n",
    "\n",
    "    # Si no hay reviews que coincidan con el filtro\n",
    "    if df_filtrado.empty:\n",
    "        print(\"No se encontraron reseñas con ese sentimiento.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Asegurar que las columnas de embeddings estén en formato de matriz\n",
    "    embedding_matrix = np.vstack(df_filtrado[\"Embeddings\"].values)\n",
    "\n",
    "    # Calcular similitud coseno\n",
    "    similitudes = cosine_similarity(query_vec, embedding_matrix)[0]\n",
    "\n",
    "    # Obtener los top_n resultados más similares\n",
    "    top_idx = np.argsort(similitudes)[-top_n:][::-1]\n",
    "    resultados = df_filtrado.iloc[top_idx].copy()\n",
    "    resultados[\"Similitud\"] = similitudes[top_idx]\n",
    "\n",
    "    return resultados[[\"Conversation\", \"Sentiment\", \"Similitud\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 112
    },
    "id": "IedAi506t1JS",
    "outputId": "46051739-03ca-4878-eee3-e19cc55bb368"
   },
   "outputs": [],
   "source": [
    "buscar_reviews(\"Great game components and rules\", sentimiento=\"POSITIVE\", top_n=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LnX9XrbdvPXh"
   },
   "source": [
    "## EJERCICIO 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WwbZbnSF7tN6"
   },
   "source": [
    "###Carga del set de datos (300 preguntas categorizadas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ih7rWkdFvRug",
    "outputId": "a69f2ea6-f641-432b-e6fe-6a3950437d33"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('/content/preguntas_tiny_towns (1).csv')\n",
    "\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q4ZN9Ob54O_n",
    "outputId": "6fed3b5a-3977-474a-d580-b932e7b052b0"
   },
   "outputs": [],
   "source": [
    "# Contar cuántas preguntas hay de cada categoría\n",
    "conteo_categorias = df['Categoría'].value_counts()\n",
    "\n",
    "print(conteo_categorias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bPyIO9SL5gIV"
   },
   "outputs": [],
   "source": [
    "df.columns = df.columns.str.strip().str.lower()\n",
    "df.rename(columns={'pregunta': 'pregunta', 'categoría': 'categoria'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vtK01MoUqIVn"
   },
   "source": [
    "### Modelo de Clasificación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3DF-QNNH-xmX",
    "outputId": "65f4e677-e568-4696-e4b0-1feca380fd0c"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report\n",
    "\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "import gensim.utils\n",
    "\n",
    "\n",
    "X = df['pregunta'].values\n",
    "y = df['categoría'].values\n",
    "\n",
    "# División train-test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\n",
    "\n",
    "# TF-IDF + LogisticRegression\n",
    "\n",
    "# Vectorizar texto con TF-IDF\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "# Entrenar LR\n",
    "lr_tfidf = LogisticRegression(max_iter=1000)\n",
    "lr_tfidf.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Predecir\n",
    "y_pred_tfidf = lr_tfidf.predict(X_test_tfidf)\n",
    "\n",
    "# Métricas TF-IDF\n",
    "print(\"*TF-IDF + Logistic Regression\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_tfidf))\n",
    "print(\"F1-score:\", f1_score(y_test, y_pred_tfidf, average='weighted'))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_tfidf, average='weighted'))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_tfidf, average='weighted'))\n",
    "print(\"\\nReporte de clasificación:\\n\", classification_report(y_test, y_pred_tfidf))\n",
    "\n",
    "# Predicción consulta nueva con TF-IDF\n",
    "consulta = [\"¿quien invento tiny towns?\"]\n",
    "consulta_vec = tfidf_vectorizer.transform(consulta)\n",
    "print(consulta)\n",
    "print(\"Predicción TF-IDF:\", lr_tfidf.predict(consulta_vec))\n",
    "\n",
    "\n",
    "#Doc2Vec + LogisticRegression\n",
    "\n",
    "# Preparar documentos etiquetados\n",
    "train_tagged = [TaggedDocument(words=gensim.utils.simple_preprocess(doc), tags=[str(i)]) for i, doc in enumerate(X_train)]\n",
    "\n",
    "# Entrenar modelo Doc2Vec\n",
    "doc2vec_model = Doc2Vec(vector_size=50, min_count=2, epochs=40)\n",
    "doc2vec_model.build_vocab(train_tagged)\n",
    "doc2vec_model.train(train_tagged, total_examples=doc2vec_model.corpus_count, epochs=doc2vec_model.epochs)\n",
    "\n",
    "# Función para vectorizar textos con Doc2Vec\n",
    "def doc2vec_vectorize(texts):\n",
    "    return [doc2vec_model.infer_vector(gensim.utils.simple_preprocess(text)) for text in texts]\n",
    "\n",
    "X_train_d2v = doc2vec_vectorize(X_train)\n",
    "X_test_d2v = doc2vec_vectorize(X_test)\n",
    "\n",
    "# Entrenar LR con vectores Doc2Vec\n",
    "lr_d2v = LogisticRegression(max_iter=1000)\n",
    "lr_d2v.fit(X_train_d2v, y_train)\n",
    "\n",
    "# Predecir\n",
    "y_pred_d2v = lr_d2v.predict(X_test_d2v)\n",
    "\n",
    "# Métricas Doc2Vec\n",
    "print(\"\\n*Doc2Vec + Logistic Regression\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_d2v))\n",
    "print(\"F1-score:\", f1_score(y_test, y_pred_d2v, average='weighted'))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_d2v, average='weighted'))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_d2v, average='weighted'))\n",
    "print(\"\\nReporte de clasificación:\\n\", classification_report(y_test, y_pred_d2v))\n",
    "\n",
    "# Predicción consulta nueva con Doc2Vec\n",
    "consulta_d2v = doc2vec_vectorize(consulta)\n",
    "print(consulta)\n",
    "print(\"Predicción Doc2Vec:\", lr_d2v.predict(consulta_d2v))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "PC5-0IITx7W_",
    "iIAAWkhfycYz",
    "QAu5yvTpywIM",
    "6t5m7X731s2f",
    "nlSccxiTFWbk",
    "UOCmN_ZqGwtl",
    "_j6ube6SHr0f",
    "Dax0ul5pIfOx",
    "0IAtzv45F3zs",
    "pgdWSsBsF-kW",
    "jGnc1t6pGHg8",
    "cOoYcGPrGV-I",
    "0nsN-b1OgkVx",
    "JwlvCLn5gsms",
    "l3MTvl4OjEnE",
    "bOU3TTiAoCsc",
    "4k4uwNY_r6JL",
    "aK9Icf_AteaQ",
    "4HZ_dhsFtkbD",
    "LnX9XrbdvPXh",
    "WwbZbnSF7tN6",
    "vtK01MoUqIVn"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
