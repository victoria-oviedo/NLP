{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PC5-0IITx7W_"
   },
   "source": [
    "## EJERCICIO 1 : Se carga el epositorio de Tiny Towns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M1Dpyc7TN3it",
    "outputId": "4fd0eb0d-3d68-4faa-8597-d8cdd63c4df8"
   },
   "outputs": [],
   "source": [
    "# Clonar el repositorio completo\n",
    "!git clone https://github.com/Augusto-Rabbia/NLP_TP1.git\n",
    "\n",
    "\n",
    "import os\n",
    "os.chdir(\"NLP_TP1/datos\")\n",
    "\n",
    "# Verificar contenido\n",
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iIAAWkhfycYz"
   },
   "source": [
    "## EJERCICIO 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QAu5yvTpywIM"
   },
   "source": [
    "### Selecci√≥n y limpieza de texto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kvNtL2QCy80N"
   },
   "source": [
    "Para este ejercicio se selecciononaron todos les textos en espa√±ol de la secci√≥n informaci√≥n y se concatenaron en un solo texto para que asi sea m√°s extenso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pQSIGezZ54tJ",
    "outputId": "2f519e74-fc65-42f4-c978-108acf024cd9"
   },
   "outputs": [],
   "source": [
    "# Carga textos en espa√±ol: review_bgg + review_externa + video\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "carpeta = \"/content/NLP_TP1/datos/informacion\"\n",
    "\n",
    "archivos_en = [\"review_bgg.txt\", \"review_externa.txt\", \"video4.txt\"]\n",
    "texto_total = \"\"\n",
    "for archivo in archivos_en:\n",
    "    with open(os.path.join(carpeta, archivo), \"r\", encoding=\"utf-8\") as f:\n",
    "        texto_total += f.read() + \"\\n\"\n",
    "\n",
    "\n",
    "print(f\"Total de caracteres: {len(texto_total)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M8nIhT4K08PL"
   },
   "source": [
    "Se hace una limpieza ligera de los datos ya que luego vamos a utilizar S-BERT y al eliminar puntuaci√≥n o normalizar demasiado, se corre el riesgo de quitarle contexto al modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ya8WOtPggqzG"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def limpiar_texto(texto):\n",
    "    texto = re.sub(r'\\s+', ' ', texto)  # reemplazar m√∫ltiples espacios y saltos de l√≠nea\n",
    "    texto = re.sub(r'[^\\w\\s√°√©√≠√≥√∫√º√±√Å√â√ç√ì√ö√ú√ë.,;:!?]', '', texto)  # eliminar s√≠mbolos raros\n",
    "    texto = texto.replace(\"*\", \"\")\n",
    "    texto = re.sub(r\"([a-z])([A-Z])\", r\"\\1 \\2\", texto)\n",
    "    texto = texto.strip()\n",
    "    return texto\n",
    "\n",
    "texto_total_limpio = limpiar_texto(texto_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6t5m7X731s2f"
   },
   "source": [
    "### Segmentaci√≥n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8R9MyHLm8PFR"
   },
   "source": [
    "Se separa el texto por saltos de l√≠nea dobles, lo que permite identificar bloques tem√°ticamente coherentes.\n",
    "\n",
    "Luego, se aplica una segmentaci√≥n \"consciente del contenido\" que conserva la estructura sem√°ntica de manera eficiente y mantiene el contexto.\n",
    "\n",
    "Finalmente, se agrupan las oraciones para evitar fragmentos demasiado cortos o ambiguos, lo cual mejora la calidad de los embeddings generados por modelos como S-BERT.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "6GZVdfx6o9To",
    "outputId": "95fea9b3-3fce-4296-ded1-68595655e33a"
   },
   "outputs": [],
   "source": [
    "!python -m spacy download es_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fm8PxydC1YxO"
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# Cargar modelo de spaCy para espa√±ol\n",
    "nlp = spacy.load(\"es_core_news_sm\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W9k-N0fr1toV",
    "outputId": "47b32626-d312-4c9f-fa25-2caa3413b6a5"
   },
   "outputs": [],
   "source": [
    "fragmentos = []\n",
    "for bloque in re.split(r'(?:\\n\\s*){2,}', texto_total):  #  esto detecta bloques separados por l√≠neas vac√≠as\n",
    "    doc = nlp(bloque.strip())\n",
    "    oraciones = [sent.text.strip() for sent in doc.sents if len(sent.text.strip()) > 10]\n",
    "\n",
    "    # Agrupar de a 2 oraciones\n",
    "    temp = []\n",
    "    for i, oracion in enumerate(oraciones):\n",
    "        temp.append(oracion)\n",
    "        if len(temp) == 2 or i == len(oraciones) - 1:\n",
    "            fragmentos.append(\" \".join(temp))\n",
    "            temp = []\n",
    "# Ver algunos ejemplos\n",
    "for i, frag in enumerate(fragmentos[:5]):\n",
    "    print(f\"Fragmento {i+1}:\\n{frag}\\n{'-'*40}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UJ9OeRXWzAqB",
    "outputId": "ad89e830-54d4-4a6b-bf01-14daf4c2c0f6"
   },
   "outputs": [],
   "source": [
    "# Se comprueba la cantidad de tokens que tienen los fragmentos\n",
    "\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Cargar el modelo\n",
    "modelo = SentenceTransformer(\"distiluse-base-multilingual-cased-v1\")\n",
    "tokenizer = modelo.tokenizer\n",
    "\n",
    "# Contar tokens de cada fragmento\n",
    "token_counts = [len(tokenizer(frag)[\"input_ids\"]) for frag in fragmentos]\n",
    "\n",
    "# Crear DataFrame\n",
    "df = pd.DataFrame({\n",
    "    \"Fragmento\": fragmentos,\n",
    "    \"N_Tokens\": token_counts\n",
    "})\n",
    "\n",
    "bins = [0, 10, 20, 30, 40, 50, 60, 80, 100, 128, float(\"inf\")]\n",
    "labels = [\n",
    "    \"0‚Äì10\", \"11‚Äì20\", \"21‚Äì30\", \"31‚Äì40\", \"41‚Äì50\",\n",
    "    \"51‚Äì60\", \"61‚Äì80\", \"81‚Äì100\", \"101‚Äì128\", \"129+\"\n",
    "]\n",
    "\n",
    "# Asignar fragmentos a rangos de tokens\n",
    "df[\"Rango_Tokens\"] = pd.cut(df[\"N_Tokens\"], bins=bins, labels=labels, right=True)\n",
    "\n",
    "# Calcular frecuencia por rango\n",
    "frecuencia = df[\"Rango_Tokens\"].value_counts().sort_index()\n",
    "\n",
    "# tabla de frecuencias\n",
    "tabla_frecuencia = frecuencia.reset_index()\n",
    "tabla_frecuencia.columns = [\"Rango de Tokens\", \"Cantidad de Fragmentos\"]\n",
    "print(tabla_frecuencia)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nlSccxiTFWbk"
   },
   "source": [
    "### Vectorizaci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ggysCeBN4Sxs"
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "from prettytable import PrettyTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "iZt3SFUg4AYX"
   },
   "outputs": [],
   "source": [
    "# Cargamos el modelo preentrenado multiling√ºe\n",
    "modelo = SentenceTransformer(\"distiluse-base-multilingual-cased-v1\")\n",
    "# Codificamos los fragmentos\n",
    "embeddings = modelo.encode(fragmentos, convert_to_tensor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d145dPlT4p5j",
    "outputId": "04fb220c-1458-4012-d135-aa63dbd6749c"
   },
   "outputs": [],
   "source": [
    "# Calculamos las puntuaciones de similitud\n",
    "puntuaciones_coseno = util.cos_sim(embeddings, embeddings)\n",
    "\n",
    "# Encontramos las puntuaciones de similitud m√°s altas\n",
    "pares = []\n",
    "for i in range(len(puntuaciones_coseno)-1):\n",
    "    for j in range(i+1, len(puntuaciones_coseno)):\n",
    "        pares.append({'index': [i, j], 'score': puntuaciones_coseno[i][j]})\n",
    "\n",
    "# Ordenamos las puntuaciones en orden decreciente\n",
    "pares = sorted(pares, key=lambda x: x['score'], reverse=True)\n",
    "\n",
    "# Creamos una tabla para mostrar los resultados\n",
    "tabla = PrettyTable()\n",
    "tabla.field_names = [\"Oraci√≥n 1\", \"Oraci√≥n 2\", \"Puntuaci√≥n de Similitud\"]\n",
    "\n",
    "# A√±adimos las filas a la tabla\n",
    "for par in pares[0:10]:\n",
    "    i, j = par['index']\n",
    "    tabla.add_row([fragmentos[i], fragmentos[j], f\"{par['score']:.4f}\"])\n",
    "\n",
    "\n",
    "print(tabla)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UOCmN_ZqGwtl"
   },
   "source": [
    "### An√°lisis de similitud de texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7mfrYK1y6goK",
    "outputId": "68013020-1d60-4c9b-ca52-5f2aa04b79dd"
   },
   "outputs": [],
   "source": [
    "consultas = [\n",
    "    \"es un juego que tine un\",\n",
    "    \"cuando se termina el juego\",\n",
    "    \"rese√±a y opiniones del juego\",\n",
    "    \"como se desarrolla una partida\"\n",
    "]\n",
    "\n",
    "consulta_embeddings = modelo.encode(consultas, convert_to_tensor=True)\n",
    "\n",
    "# Calcular similitudes coseno\n",
    "resultados = util.cos_sim(consulta_embeddings, embeddings)\n",
    "\n",
    "# Mostrar los fragmentos m√°s similares por cada consulta\n",
    "top_k = 2\n",
    "for i, consulta in enumerate(consultas):\n",
    "    print(f\"\\nüîç Consulta: {consulta}\")\n",
    "    valores_sim, idxs = resultados[i].topk(top_k)\n",
    "    for score, idx in zip(valores_sim, idxs):\n",
    "        print(f\"\\n* Similitud: {score.item():.4f}\")\n",
    "        print(f\"{fragmentos[idx]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_j6ube6SHr0f"
   },
   "source": [
    "### M√©tricas de Semejanza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "kq0DL-m4yy5N",
    "outputId": "2282de81-c07a-4b9f-ff89-575cdef4c15d"
   },
   "outputs": [],
   "source": [
    "!pip install python-Levenshtein jellyfish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PMgiASmTYa1L"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.spatial.distance import jaccard\n",
    "from Levenshtein import distance as levenshtein_distance\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import jellyfish\n",
    "\n",
    "def dice_similarity(s1, s2):\n",
    "    set1, set2 = set(s1.split()), set(s2.split())\n",
    "    if not set1 or not set2:\n",
    "        return 0.0\n",
    "    return 2 * len(set1 & set2) / (len(set1) + len(set2))\n",
    "\n",
    "def buscar_similares(frase_consulta, top_k=3):\n",
    "    print(f\"\\nüîç Frase de b√∫squeda: {frase_consulta}\")\n",
    "\n",
    "    # Vector S-BERT de la consulta\n",
    "    vector_consulta = modelo.encode([frase_consulta], convert_to_tensor=True)\n",
    "\n",
    "    # ---------- M√âTRICA 1: Coseno ----------\n",
    "    similitudes_coseno = cosine_similarity(vector_consulta, embeddings)[0]\n",
    "    top_coseno_idx = np.argsort(similitudes_coseno)[-top_k:][::-1]\n",
    "\n",
    "    print(\"\\nüìê Resultados por *Similitud del coseno*:\")\n",
    "    for idx in top_coseno_idx:\n",
    "        print(f\"  ({similitudes_coseno[idx]:.3f}) {fragmentos[idx][:100]}...\")\n",
    "\n",
    "    # ---------- M√âTRICA 2: Jaccard ----------\n",
    "    vectorizer = CountVectorizer(binary=True)\n",
    "    binarized = vectorizer.fit_transform([frase_consulta] + fragmentos)\n",
    "    jaccard_scores = [\n",
    "        1 - jaccard(binarized[0].toarray()[0], binarized[i+1].toarray()[0])\n",
    "        for i in range(len(fragmentos))\n",
    "    ]\n",
    "    top_jaccard_idx = np.argsort(jaccard_scores)[-top_k:][::-1]\n",
    "\n",
    "    print(\"\\nüìê Resultados por *Distancia de Jaccard*:\")\n",
    "    for idx in top_jaccard_idx:\n",
    "        print(f\"  ({jaccard_scores[idx]:.3f}) {fragmentos[idx][:100]}...\")\n",
    "\n",
    "    # ---------- M√âTRICA 3: Dice ----------\n",
    "    dice_scores = [dice_similarity(frase_consulta, frag) for frag in fragmentos]\n",
    "    top_dice_idx = np.argsort(dice_scores)[-top_k:][::-1]\n",
    "\n",
    "    print(\"\\nüìê Resultados por *Similitud de Dice*:\")\n",
    "    for idx in top_dice_idx:\n",
    "        print(f\"  ({dice_scores[idx]:.3f}) {fragmentos[idx][:100]}...\")\n",
    "\n",
    "\n",
    "    return vector_consulta, top_coseno_idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KAx2Apj0z9g2",
    "outputId": "5d394798-de5c-44c1-e0dd-d80877a8fcd5"
   },
   "outputs": [],
   "source": [
    "vector_consulta, top_coseno_idx = buscar_similares(\"cuando o como finaliza el juego para un los participantes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G__dpKob-jL_"
   },
   "source": [
    "Para realizar la b√∫squeda sem√°ntica entre fragmentos de texto, probamos distintas m√©tricas de Semejanza:\n",
    "\n",
    "**Similitud del coseno**, que utiliza vectores densos de embeddings para capturar significado m√°s all√° de palabras literales.\n",
    "\n",
    "**Distancia de Jaccard** y **Similitud de Dice**, que comparan palabras presentes en los textos en forma binaria.\n",
    "\n",
    "Otras m√©tricas como Levenshtein o Jaro-Winkler se descartaron porque miden diferencias a nivel de caracteres y no son adecuadas para evaluar similitud sem√°ntica entre textos largos o fragmentados.\n",
    "\n",
    "**La Similitud del coseno fue la que mejor reflej√≥ la relaci√≥n sem√°ntica entre la consulta y los fragmentos, por lo que se eligi√≥ como m√©trica principal para el an√°lisis.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dax0ul5pIfOx"
   },
   "source": [
    "### Visualizaci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M5Ij5xwvPDNv"
   },
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "def visualizar_tsne_3D(embeddings, vector_consulta, fragmentos, top_idx=None):\n",
    "    import numpy as np\n",
    "\n",
    "    # Unir embeddings + consulta\n",
    "    all_vectors = np.vstack([vector_consulta, embeddings])\n",
    "\n",
    "    # Aplicar t-SNE\n",
    "    tsne = TSNE(n_components=3, perplexity=30, n_iter=1000, random_state=42, init='pca')\n",
    "    emb_3d = tsne.fit_transform(all_vectors)\n",
    "\n",
    "    # Separar los puntos\n",
    "    consulta_3d = emb_3d[0]\n",
    "    frag_3d = emb_3d[1:]\n",
    "\n",
    "    # Graficar\n",
    "    fig = plt.figure(figsize=(10, 7))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "    # Fragmentos\n",
    "    ax.scatter(frag_3d[:, 0], frag_3d[:, 1], frag_3d[:, 2], alpha=0.6, label='Fragmentos')\n",
    "\n",
    "    # Consulta\n",
    "    ax.scatter(consulta_3d[0], consulta_3d[1], consulta_3d[2], c='red', s=100, label='Frase de b√∫squeda')\n",
    "\n",
    "    # M√°s similares\n",
    "    if top_idx is not None and len(top_idx) > 0:\n",
    "        ax.scatter(frag_3d[top_idx, 0], frag_3d[top_idx, 1], frag_3d[top_idx, 2],\n",
    "                   c='green', s=60, label='M√°s similares')\n",
    "\n",
    "    ax.set_title(\"Visualizaci√≥n 3D con t-SNE\")\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "\n",
    "    return emb_3d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 653
    },
    "id": "0FU2kcVpPD9d",
    "outputId": "0ee43ca0-3135-4266-a493-e0678ff81325"
   },
   "outputs": [],
   "source": [
    "emb_3d_tsne = visualizar_tsne_3D(\n",
    "    embeddings=embeddings,\n",
    "    vector_consulta=vector_consulta,\n",
    "    fragmentos=fragmentos,\n",
    "    top_idx=top_coseno_idx  # o top_jaccard_idx, etc.\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C5hOv_maLTiS"
   },
   "source": [
    "## EJERCICIO 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0IAtzv45F3zs"
   },
   "source": [
    "### Cargamos el texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uGVsIb3YLTiT",
    "outputId": "3d52adc5-9a2a-4ebe-de02-9c312214cd92"
   },
   "outputs": [],
   "source": [
    "#cargamos el texto\n",
    "ruta = \"/content/NLP_TP1/datos/informacion/manual.txt\"\n",
    "\n",
    "with open(ruta, \"r\", encoding=\"utf-8\") as file:\n",
    "    texto_manual = file.read()\n",
    "\n",
    "# An√°lisis b√°sico\n",
    "num_caracteres = len(texto_manual)\n",
    "num_palabras = len(texto_manual.split())\n",
    "\n",
    "print(f\" El texto contiene {num_caracteres} caracteres y {num_palabras} palabras.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xHhrL11BLTiU"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Limpieza m√≠nima\n",
    "texto_manual_limpio = re.sub(r'\\s+', ' ', texto_manual).strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pgdWSsBsF-kW"
   },
   "source": [
    "### Segmentaci√≥n con spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "Xnx8IVJ-sal4",
    "outputId": "e8d784ea-bf26-4ff2-f0d2-115c7a1720c7"
   },
   "outputs": [],
   "source": [
    "!python -m spacy download en_core_web_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xIfNK3HZsVve"
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "# spaCy en ingl√©s\n",
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0xveLakYrzHg"
   },
   "outputs": [],
   "source": [
    "# Segmentaci√≥n del texto\n",
    "doc_total = nlp(texto_manual_limpio)\n",
    "fragmentos = [sent.text.strip() for sent in doc_total.sents]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jGnc1t6pGHg8"
   },
   "source": [
    "### POS y NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "KBhIByBjL60l",
    "outputId": "b2252ade-16a0-468c-ea00-20ccc1dbd35d"
   },
   "outputs": [],
   "source": [
    "!pip install spacy gliner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "812f4c758b184b8bb8abdede9f64f5f3",
      "0f565fb4b6df460d9738c3917e2caadc",
      "4f5959514974417abd177f534676f4a5",
      "4c4e45a4cfea4c63a809da6b6e884d00",
      "0f584c2069034d54a9418c15263ea0c8",
      "b622b13c47cd48b59d6f7732130f82c3",
      "38f92b3a35a543299a616c32a2f1fdad",
      "ab959952fee843628254416cfee9a102",
      "69ef55f4e74746d1aa131548d71c562f",
      "ee11fb1192a0490d910b16115eb70495",
      "39b4f60dff4745a89e25261cb6146d56",
      "68159a3520d545509c6ae09404ae3f20",
      "947c0686d9434d34bd70ddb52d46c12f",
      "3992b8ff804542a1b2ea5b5f853d4f43",
      "f96aec393950420e89a88bab650b6c93",
      "fec13fa614c24ab5b75ef0255e49926c",
      "960dd8e35e644038b3b68175a8d3a86f",
      "261f3377716c4a71833e60ff3baebaab",
      "3632321a45d049009de775675aabd4b2",
      "7f7b0fbfc70d4d808367bad39d8735f9",
      "fcecd4977a9348a099139682c4da0944",
      "477e9ba355114edcb87313b20e4aeacd",
      "03b00a9ba90c47fb999da65aed355f5c",
      "c1831c0d7a084acba74fb42852561c86",
      "c23cecd42b5d4ea48640e3362939b0aa",
      "7d61badccdbf4a4aa6d8b13eca08778d",
      "4a67d44e59a1429e94281229f7ac7859",
      "4fe04329d0b84b7c8f4b597c4cce45d5",
      "098a2b470be94dec8688929bb316856c",
      "c7d47d62daad4ffb8234df3d6c15e6be",
      "e4298b42331145c5aacf2a387439969a",
      "4046e219970d43299c9b21b68c0098f3",
      "632f656e1c6b4a2399b3a9f85bc0d5f1",
      "796cebc39fb044228df434055efbc829",
      "f1351e8b8927415295da08152a1fa96b",
      "4cecea9eecde4fe0a3cb363a3aeb09e9",
      "d58369e141c5455d9e0e489aed01df52",
      "cf1779128212435784d6161222bcfe44",
      "776b2233e17449bcbe047bc69c88f9a6",
      "d396657d0e2f423cbcab1e37c727d4b2",
      "b2a6c131f7ba417eaccc54c05b106900",
      "cade3f9597fe4479b867f244879952fb",
      "67937c8ff9df41b59a6866cdbd78b33c",
      "c0626dc13c9e4435bb3232bc2b137ed8",
      "9aaabeed93ab4e549b92ed94c7a69f4d",
      "0f29377c90684f819c8aa8264f20407a",
      "6f3d2ae5f36c41f6aa859ca78b71ecf0",
      "bd5db73b63914891b61b8dc9500893bd",
      "630cdce453f04371b297491fd47208c8",
      "2e6b15fdb2f2492f92faef90343f28c1",
      "448723d0a55b4dc2ade2d53f58656f4c",
      "f8ee261726d349d4b5e91a1ef39b89e1",
      "355fc8bb4b884885b233cb388ee30d67",
      "8d2dd4ca90504bd6b2955d507e5ae0af",
      "a7e86350f0ee4d03b45ad961b4fa1d64",
      "65413bb867d84709a1f94cbbc229aead",
      "26da2620b4584c04b9278aa3a668a57c",
      "5320d38147a3437587219cd795fcbf1b",
      "75254230daac4af3ba0eefd1d5091065",
      "c5fa6e11b31742c48db042a6a83506c0",
      "d8f23f3f236849b8a0a052bc74943553",
      "15fc5e2ecc86494bbe913109003587c9",
      "dc432ff2358b43538b07ccdae6421e24",
      "b776d6d56e05447c80c7ed7ebdf9e3c7",
      "93090c620584496a906a65fea44468c1",
      "30c3c87719304a4db962b5ed75bf7412",
      "7c88df7b5a054996b6bccc373b8c9a58",
      "819e6953d6304dfe96c1e42a9a22d478",
      "cea3a1e8d78f4bc685926685a7daeddd",
      "fd5551bdee8845bdb17a027e66433c88",
      "b2f8c611729047208c1081c9401ce946",
      "9105387cb1c448daa4f25ad7d1e80bc9",
      "8131c33e29014f448f118a871fdfeebf",
      "4207d293145544d6bb176d2450065ff8",
      "4b2707e6ddfd456186b71be11b4bd6e4",
      "d2ae7d8c86234196a7c73cca12df4cf7",
      "e8e49974efd5465c8145f0b3dbd6c73c",
      "91b211aa9ec94695aa51788448dbb6a7",
      "115420ca04344f54ba76285ebf666b56",
      "a49ce546355b4767ae35611b40740076",
      "2771542bd3b74b059f6130c62a295bf8",
      "cd6ec15f30dd421b854c58bd26ecf8bf",
      "253b04887ecf4d3faac56d1b70b2ed7d",
      "4053458e6b15478b98d6aac079947495",
      "a3cd235f85bd4cc4adb640e39a563dab",
      "9a9a5a1c7cff41b3b22f86bc4dbace8c",
      "eb76bcfa1d13450e867d68c6da1453a0",
      "82244aaacb934220a04c60bc9013ec87"
     ]
    },
    "collapsed": true,
    "id": "q7c9IHaSrK1c",
    "outputId": "86ebe5fc-e37f-46c3-bff9-b8e29ebee666"
   },
   "outputs": [],
   "source": [
    "from gliner import GLiNER\n",
    "\n",
    "# GLiNER multiling√ºe\n",
    "gliner = GLiNER.from_pretrained(\"urchade/gliner_multi-v2.1\")\n",
    "gliner.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hz3LtUT_tpip",
    "outputId": "b68891b9-f48e-4ee0-c035-2cadb275407c"
   },
   "outputs": [],
   "source": [
    "sustantivos_por_fragmento = []\n",
    "entidades_por_fragmento = []\n",
    "\n",
    "for i, frag in enumerate(fragmentos):\n",
    "\n",
    "    # spaCy: extraer sustantivos\n",
    "    doc_frag = nlp(frag)\n",
    "    nouns = [token.text for token in doc_frag if token.pos_ in {\"NOUN\", \"PROPN\"}]\n",
    "    sustantivos_por_fragmento.append(nouns)\n",
    "    print(\"Sustantivos detectados (POS):\", nouns)\n",
    "\n",
    "    # GLiNER: entidades personalizadas\n",
    "    labels = [\"person\", \"book\", \"location\", \"date\", \"character\", \"board game\", \"GameComponent\",\n",
    "              \"ResourceType\",\"BuildingType\",\"Role\", \"RuleName\"]\n",
    "    ents = gliner.predict_entities(frag, labels, threshold=0.4)\n",
    "    entidades_por_fragmento.append(ents)\n",
    "\n",
    "    for ent in ents:\n",
    "        print(f\" - {ent['text']} => {ent['label']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T71O1C68Oxen"
   },
   "outputs": [],
   "source": [
    "sustantivos_ner = []\n",
    "\n",
    "for ents in entidades_por_fragmento:\n",
    "    # Extraer solo el texto de las entidades (que son los sustantivos o nombres detectados por NER)\n",
    "    sustantivos_ner.append([ent[\"text\"] for ent in ents])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AGkmWIOja_6J",
    "outputId": "c200235f-7421-41e6-b6e4-a47dff3f86f0"
   },
   "outputs": [],
   "source": [
    "print(sustantivos_ner)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "djlx0SDdmGTE"
   },
   "source": [
    "### B√∫squeda de similitud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cOoYcGPrGV-I"
   },
   "source": [
    "#### Vectorizaci√≥n con FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "rhIx5cgbFkPq",
    "outputId": "1c8baab7-d5a9-4822-8b90-37506be6b1a6"
   },
   "outputs": [],
   "source": [
    "!pip install fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A5-MTuvQEfJc",
    "outputId": "0687eb4d-5f0e-4392-9fc7-4c0cd24670b9"
   },
   "outputs": [],
   "source": [
    "import fasttext\n",
    "import fasttext.util\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Descargar modelo en ingl√©s\n",
    "fasttext.util.download_model('en', if_exists='ignore')\n",
    "ft_model = fasttext.load_model('cc.en.300.bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0nsN-b1OgkVx"
   },
   "source": [
    "#### M√©tricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HareUoiFggEj"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import Levenshtein\n",
    "import jellyfish\n",
    "from sklearn.metrics.pairwise import cosine_similarity as sk_cosine_similarity\n",
    "\n",
    "# --- Funciones m√©tricas ---\n",
    "\n",
    "def cosine_similarity(vec1, vec2):\n",
    "    if np.linalg.norm(vec1) == 0 or np.linalg.norm(vec2) == 0:\n",
    "        return 0.0\n",
    "    return np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))\n",
    "\n",
    "def jaccard_distance(str1, str2):\n",
    "    set1, set2 = set(str1), set(str2)\n",
    "    inter = set1.intersection(set2)\n",
    "    union = set1.union(set2)\n",
    "    return 1 - len(inter) / len(union) if union else 1.0\n",
    "\n",
    "def dice_similarity(str1, str2):\n",
    "\n",
    "    def bigrams(s):\n",
    "        return set([s[i:i+2] for i in range(len(s)-1)]) if len(s) > 1 else set()\n",
    "    bigr1 = bigrams(str1)\n",
    "    bigr2 = bigrams(str2)\n",
    "    inter = bigr1.intersection(bigr2)\n",
    "    return 2 * len(inter) / (len(bigr1) + len(bigr2)) if (len(bigr1)+len(bigr2)) > 0 else 0.0\n",
    "\n",
    "def levenshtein_distance(str1, str2):\n",
    "    return Levenshtein.distance(str1, str2)\n",
    "\n",
    "def jaro_winkler_similarity(str1, str2):\n",
    "    return jellyfish.jaro_winkler_similarity(str1, str2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JwlvCLn5gsms"
   },
   "source": [
    "#### Funciones de busqueda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "01iwurDBQ3ld"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Aplanar la lista de listas de sustantivos filtrados por NER y pasar a min√∫sculas\n",
    "sustantivos_filtrados = [noun.lower() for sublist in sustantivos_ner for noun in sublist]\n",
    "\n",
    "# Quitar duplicados\n",
    "sustantivos_unicos = list(set(sustantivos_filtrados))\n",
    "\n",
    "\n",
    "# --- Funciones de b√∫squeda por cada m√©trica ---\n",
    "\n",
    "def buscar_por_coseno(query, lista, ft_model, top_k=3):\n",
    "    query_vec = ft_model.get_word_vector(query.lower())\n",
    "    similitudes = []\n",
    "    for palabra in lista:\n",
    "        vec = ft_model.get_word_vector(palabra)\n",
    "        sim = cosine_similarity(query_vec, vec)\n",
    "        similitudes.append((palabra, sim))\n",
    "    similitudes = sorted(similitudes, key=lambda x: x[1], reverse=True)\n",
    "    return similitudes[:top_k]\n",
    "\n",
    "def buscar_por_jaccard(query, lista, top_k=3):\n",
    "    distancias = []\n",
    "    for palabra in lista:\n",
    "        dist = jaccard_distance(query.lower(), palabra)\n",
    "        distancias.append((palabra, dist))\n",
    "    distancias = sorted(distancias, key=lambda x: x[1])\n",
    "    return distancias[:top_k]\n",
    "\n",
    "def buscar_por_levenshtein(query, lista, top_k=3):\n",
    "    distancias = []\n",
    "    for palabra in lista:\n",
    "        dist = levenshtein_distance(query.lower(), palabra)\n",
    "        distancias.append((palabra, dist))\n",
    "    distancias = sorted(distancias, key=lambda x: x[1])\n",
    "    return distancias[:top_k]\n",
    "\n",
    "def buscar_por_dice(query, lista, top_k=3):\n",
    "    similitudes = []\n",
    "    for palabra in lista:\n",
    "        sim = dice_similarity(query.lower(), palabra)\n",
    "        similitudes.append((palabra, sim))\n",
    "    similitudes = sorted(similitudes, key=lambda x: x[1], reverse=True)\n",
    "    return similitudes[:top_k]\n",
    "\n",
    "def buscar_por_jaro_winkler(query, lista, top_k=3):\n",
    "    similitudes = []\n",
    "    for palabra in lista:\n",
    "        sim = jaro_winkler_similarity(query.lower(), palabra)\n",
    "        similitudes.append((palabra, sim))\n",
    "    similitudes = sorted(similitudes, key=lambda x: x[1], reverse=True)\n",
    "    return similitudes[:top_k]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l3MTvl4OjEnE"
   },
   "source": [
    "#### Busqueda de Similitud con distancias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vH7VM5Wwj-8A"
   },
   "source": [
    "Para una ‚Äúsimilitud textual‚Äù (si se parecen las palabras de forma escrita) las m√©tricas como Jaccard, Levenshtein, Dice, Jaro-Winkler son adecuadas porque miden la similitud basada en caracteres o tokens. Entre estas m√©tricas, Jaro-Winkler suele ser la m√°s efectiva porque pondera los prefijos comunes y corrige bien errores de tipeo al inicio de las palabras,.\n",
    "\n",
    "Pero si pensamos en ‚Äúsimilitud sem√°ntica‚Äù (relaci√≥n de significado o contexto) similitud por coseno es la mejor opci√≥n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0C5f3DODg7dW"
   },
   "outputs": [],
   "source": [
    "# Funci√≥n general que muestra todo\n",
    "def buscar_similitudes(query, palabras, ft_model, top_k=3):\n",
    "    print(f\"\\nSimilitud coseno con FastText para '{query}':\")\n",
    "    for palabra, score in buscar_por_coseno(query, palabras, ft_model, top_k):\n",
    "        print(f\"  {palabra}: {score:.3f}\")\n",
    "\n",
    "    print(f\"\\nSimilitud de Jaccard para '{query}':\")\n",
    "    for palabra, score in buscar_por_jaccard(query, palabras, top_k):\n",
    "        print(f\"  {palabra}: {score:.3f}\")\n",
    "\n",
    "    print(f\"\\nSimilitud de Levenshtein para '{query}':\")\n",
    "    for palabra, score in buscar_por_levenshtein(query, palabras, top_k):\n",
    "        print(f\"  {palabra}: {score:.3f}\")\n",
    "\n",
    "    print(f\"\\nSimilitud de Dice para '{query}':\")\n",
    "    for palabra, score in buscar_por_dice(query, palabras, top_k):\n",
    "        print(f\"  {palabra}: {score:.3f}\")\n",
    "\n",
    "    print(f\"\\nSimilitud de Jaro-Winkler para '{query}':\")\n",
    "    for palabra, score in buscar_por_jaro_winkler(query, palabras, top_k):\n",
    "        print(f\"  {palabra}: {score:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tJEmiduWhT6-",
    "outputId": "4ae49d03-fb84-41ad-b31e-c562ae7ef449"
   },
   "outputs": [],
   "source": [
    "buscar_similitudes(\"Fyni tonw\", sustantivos_unicos, ft_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "48eatprhi1vI",
    "outputId": "53da03c1-4544-46e4-d80a-5a0ac5e111b7"
   },
   "outputs": [],
   "source": [
    "buscar_similitudes(\"Construct\", sustantivos_unicos, ft_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bOU3TTiAoCsc"
   },
   "source": [
    "## EJERCICIO 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "IICUDvEUoaAB",
    "outputId": "59a53a22-1b6d-4f10-fdb4-d91372d018db"
   },
   "outputs": [],
   "source": [
    "!pip install langdetect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AT8xgv5soMHw",
    "outputId": "05332542-fb26-48ec-cd16-82119d6f5672"
   },
   "outputs": [],
   "source": [
    "from langdetect import detect, DetectorFactory\n",
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "\n",
    "DetectorFactory.seed = 0\n",
    "\n",
    "# Carpeta ra√≠z donde est√°n las carpetas 'estadisticas', 'informacion', 'relaciones'\n",
    "root_dir = '/content/NLP_TP1/datos'\n",
    "\n",
    "resultados = []\n",
    "\n",
    "for carpeta, subcarpetas, archivos in os.walk(root_dir):\n",
    "    for archivo in archivos:\n",
    "        ruta = os.path.join(carpeta, archivo)\n",
    "\n",
    "        if archivo.endswith(('.txt', '.csv')):\n",
    "            try:\n",
    "                with open(ruta, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "                    texto = f.read()\n",
    "                if texto.strip():\n",
    "                    idioma = detect(texto)\n",
    "                else:\n",
    "                    idioma = 'vac√≠o'\n",
    "                resultados.append({'archivo': ruta, 'idioma': idioma})\n",
    "            except Exception as e:\n",
    "                print(f\"Error leyendo {ruta}: {e}\")\n",
    "\n",
    "# Creamos el DataFrame con resultados\n",
    "df_idiomas = pd.DataFrame(resultados)\n",
    "\n",
    "print(df_idiomas)\n",
    "\n",
    "# Copiamos los archivos en carpetas separadas seg√∫n el idioma\n",
    "carpeta_destino = '/content/NLP_TP1/datos_separados'\n",
    "\n",
    "os.makedirs(carpeta_destino, exist_ok=True)\n",
    "\n",
    "for _, fila in df_idiomas.iterrows():\n",
    "    archivo = fila['archivo']\n",
    "    idioma = fila['idioma']\n",
    "\n",
    "    carpeta_idioma = os.path.join(carpeta_destino, idioma)\n",
    "    os.makedirs(carpeta_idioma, exist_ok=True)\n",
    "\n",
    "    nombre_archivo = os.path.basename(archivo)\n",
    "    destino = os.path.join(carpeta_idioma, nombre_archivo)\n",
    "\n",
    "    shutil.copy2(archivo, destino)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4k4uwNY_r6JL"
   },
   "source": [
    "## EJERCICIO 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aK9Icf_AteaQ"
   },
   "source": [
    "### An√°lisis de sentimientos (BERT multiling√ºe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZArC_OMkr8sJ"
   },
   "outputs": [],
   "source": [
    "# Reemplaz√° con el nombre correcto de tu archivo\n",
    "df = pd.read_csv(\"/content/NLP_TP1/datos/informacion/df_foros_bgg.csv\")\n",
    "\n",
    "# Nos quedamos solo con las Reviews\n",
    "reviews_df = df[df[\"Category\"] == \"Reviews\"].copy()\n",
    "reviews_df.dropna(subset=[\"Conversation\"], inplace=True)\n",
    "reviews_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 194,
     "referenced_widgets": [
      "4503365125b946aea036a2fdc3bedade",
      "c2a669bf0ef34b559c6e8d3260f895b7",
      "89f73186cba64cf394ac0c93a082dea3",
      "df8f9278ba434a5daf14086ac3ac0469",
      "a9922e7f4ef643ff89fa76c60b8a3bf2",
      "339fc1a6802a4fab99e3279f8e7862d8",
      "76d46a6dbf5e4b6887db9be22b9fdf62",
      "88fd6670d14f42bca019a1414f73e904",
      "9a2ceeffdf8a4271b18ef2ff0dcd5d57",
      "058e1f71d42c44de853507375c81a7da",
      "ad75a93e6eb34f4f9258237119a8a13f",
      "f5583beb320b45388ba6b52e9ee1b521",
      "4ab3c96816454bf8bc665041b0555e2b",
      "55b708e530cc47fc81e5a47f1a82c88a",
      "62e5d1a6e43149b79a2f35f51d81cd8a",
      "03b95d94380e40df9d4b4bdb8449481e",
      "9711366791c545d28923be6b5e3347c4",
      "b8cb96092b2a4f13b225dd58960d03bf",
      "8106b6a62eb7429da15fdfc1e4162a27",
      "a53f58090a074ad4a38b5767ce51619b",
      "65f94588979b45fda183f5451dd94e00",
      "c6eadd4367c5451cbb84d7b6dea5b261",
      "97bb78589b2d4367a28401b14fb26db8",
      "07661b8434384636b0e3eed3ea958d36",
      "96ce4523443d49108cec37e3e3ecc172",
      "101a37ef2fdf41c0a8d0de172c755ce6",
      "72872ca55680467b99d54b21dc206d4b",
      "57dcc33ca39246d28bcfdc09539f8434",
      "f9719f4f23294a74a2a381341ed4fd40",
      "d730da29c0ee4bf8a9fe2f7e2e439939",
      "ac9a7bbd36c54f089cddec3bc2d977e5",
      "e53ed39fc74d4614adea12dfc7b9364d",
      "ffa1887f3c2e400ab3a46a210314f2a7",
      "00e162f0a94a4bf48d624bb0cb4acc92",
      "26b1421f388f4e959d5e33ed1ecc06e8",
      "2f7b3b537fce4a608f4e4fd2f53636be",
      "88ecd4b408444cd99a58e8be576d8b6c",
      "ea449c51ad644bc7a7976649d499145c",
      "f74e1ddc99474f7d90e2cf7fbdcce5a2",
      "ad9419e2b2f64fc1a8facac7d9429dd5",
      "a4edc992dfcb4c3faaf5bfd8902b87de",
      "e67d1ea581f24668bbb274d9686266eb",
      "e23aabd9c54143a8b2a607354c9bde78",
      "5579aabdb6c24aeea40a056cbadc1589",
      "63766e72eb7f40f08e9802e00e5011ad",
      "f38a3b20cdea40dc933f041c873d6bc1",
      "5fb8e5cf5b374c738208d931d526543d",
      "b50692cac63f47b291df9395f4475b0e",
      "5a5a21f278744bc79b4b9ceca04288e4",
      "ac7ecdaee5aa42ac96718168d68c257a",
      "f627f713715648229cd8ce52774c5fce",
      "4ebe5dbd2ccc43f2ac709f1755170bae",
      "b7c1ac2d1c3e4f35854738434b9fb12f",
      "36b5668b01124c2c9127977fcfd89658",
      "0010d2098e8e469d8c4978aae59cac56"
     ]
    },
    "collapsed": true,
    "id": "RHoSPCU1sKLU",
    "outputId": "41e9be2c-6a3a-426b-fead-0db15161a4a2"
   },
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification, pipeline\n",
    "\n",
    "# Modelo entrenado en varios idiomas\n",
    "model_name = \"nlptown/bert-base-multilingual-uncased-sentiment\"\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "# Pipeline de an√°lisis de sentimientos\n",
    "nlp = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "# Funci√≥n para convertir estrellas a polaridad\n",
    "def stars_to_label(label):\n",
    "    stars = int(label.split()[0])\n",
    "    if stars <= 2:\n",
    "        return \"NEGATIVE\"\n",
    "    elif stars == 3:\n",
    "        return \"NEUTRAL\"\n",
    "    else:\n",
    "        return \"POSITIVE\"\n",
    "\n",
    "# Aplicar an√°lisis a cada review\n",
    "reviews_df[\"Sentiment_raw\"] = reviews_df[\"Conversation\"].apply(lambda x: nlp(x[:512])[0])  # truncar a 512 tokens\n",
    "reviews_df[\"Sentiment\"] = reviews_df[\"Sentiment_raw\"].apply(lambda x: stars_to_label(x[\"label\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e7slGgvPtBAl"
   },
   "outputs": [],
   "source": [
    "reviews_df.to_csv(\"reviews_con_sentimientos.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "tpO2JRDDsj0g",
    "outputId": "1e7ec3ab-f809-4cce-e076-9e716124f14b"
   },
   "outputs": [],
   "source": [
    "reviews_df[[\"Conversation\", \"Sentiment_raw\", \"Sentiment\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4HZ_dhsFtkbD"
   },
   "source": [
    "### Sistema de b√∫squeda sem√°ntica + filtro por sentimiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424,
     "referenced_widgets": [
      "b1c789458e5f492ca82ab2f736e8aef1",
      "415c323f489845cdaeee86bb8087d22e",
      "5fcaa91c3a104f36a03a0182168b2312",
      "a82ca064f80645469b437172b99b4933",
      "4ad5b3e03432409a8c7cffcb7c02f955",
      "1551c81bd6674fe7b00bd51ef69e184c",
      "8954d0a0e8ae42e6af827751e7355a24",
      "0fe8ddb8c0e848079560b3f3e260dbdc",
      "6617d628aea2442ba43b9796258c5a14",
      "bdb2f8fa66a34a39bc208f31f88b2eb3",
      "6c97d2b421c746119d8a1eb2be9f7a57",
      "859503c7cff649c48165723b3dacd5e0",
      "01cc9719a60e4e37b2d56ed6c64f041b",
      "b9f97858c2f645b899c7f7e698fe477b",
      "4f38353c6f4a47fd950e7163e02dc2d8",
      "c607a8c665434a4bbd9055b7d47dc1f1",
      "8093ed32d166416dba85f9b58b146395",
      "8321e6a2d6bf42d48da3497e16f07a6b",
      "56e646124e164d75ac382e9db2c13b34",
      "0eb09a93dd8542eb9c122bd4594b1a09",
      "9899d4e5ecae49e18fee61057a0294dd",
      "9c5d13a300c24e8291e0e3044f8ba43d",
      "e54f2156d9b94e88b6890c0f6ffa4a9d",
      "80ab24347c884dc6ad88a2038df0aafd",
      "677d26e211814e3c8e64f11613cd2423",
      "0f3323149c2645e39849c4f6b17c81bc",
      "3365ce085a544edbbc61155fd2f2bd2f",
      "f1b5ce45347c48ebae09b04048510638",
      "71bf15b5bdb94d5b96402756fdadbad7",
      "1bc29105e7e9425498ddd9b991a0676a",
      "b7a3adf1cc1d45fa9b3690470db89d06",
      "4c3064d7b4c845f094e76f0c0d810d67",
      "360a2ece72e24b9cafdab13b4b9a73a3",
      "b183ee91f80d4caab1ba48528c119602",
      "36bd8ff523764d588472db6ba7dc22aa",
      "49f50b90e9584958b9c73770099754ce",
      "e4f101a6cdd049d78c53caab45daffa7",
      "109d09a4fd9440e48c05794909ed7244",
      "b873d45c8be04ed38cee9df08924e727",
      "b67e0fb6b0f44423a34a06613b824089",
      "4cc2f9d77f2243e9aea061e2cd6ead02",
      "10514131280844dab2a0a9d5b909ac03",
      "1243a79473a74f9daee5c97f3461435f",
      "cc1c579fd6e24e0f94e7f1c5d41336c4",
      "aefaf4bed2184a5c88a988d086a07858",
      "e7722c24b9284c53b96397914e735d19",
      "6f95dc57c2624c6ebab222ccb311d344",
      "0f3e065fcd6a4225b2620aa39429482b",
      "bc054cbcd7384e10a6c3f79a1e13a64b",
      "30299e98d1b04ca7a2cddf060da16013",
      "e9ec8bf255394ffe9cb62df62b2a79a3",
      "814a9e6935014a3bab2a180167f3f0a2",
      "b98f8f3420ba48f685041b1b4d3e3dc8",
      "e8ca5ab619cd4abd98f2799d423daadc",
      "1bcf88d8b1b740c586b977c79e3852e9",
      "07e9babd68fc43f6be8c461eb1bcc146",
      "db6812d698c147b98b6ff59e12995e44",
      "949bdcdd45764a53a0d9e948dce66a27",
      "94756aa356d64dbebf5e756b53667dc2",
      "a8d7f49127184f4f81bb5f14f4e09ae3",
      "c4ce570fad4143ca81b3d1ddc6d86b87",
      "7c845190ecd842cba458d7b0cb38285e",
      "a252c5fd7eed44d48d99ab25593118ad",
      "38eb7112d3684c01ab770f3690e33b33",
      "ba2549f9a34a4686a330b438e70e582f",
      "96031ca483dd44f7b2931ce10d911b22",
      "1636cdb8a46e419e845f7d7fc5ac6469",
      "4becdfa475814548b15cd12758b6461d",
      "089045e25866440384ac002c33cf1777",
      "857ba887dfdd4be38a9ee147085213f6",
      "c9d5d3828c4f44a2b449e45f8c96cc4e",
      "806d3f1e4e99490eac4aef1941d9d6dd",
      "9fc189bf98464e94b7d8f46f41065b6b",
      "09a7114cf45f4d9781bab428a85f98bb",
      "052a68c000414f529e7173c74c5e9de3",
      "753cfc1e990e425bb2c3772614e128d5",
      "812066089ad141809d4c9cad06492d5f",
      "aea7c54c456e41ebbaad3e1161ac06ba",
      "5c2b083493cc4814b3cf76f7a652cd4d",
      "c970385d7716461e960047d0e39a256b",
      "512b46eccfc64bacaea09f18eab9ddc8",
      "943fbbc3503747648a1854c764b2ee00",
      "0fed38496ec949ee9d662046d1846ede",
      "619d60315b104a17a8d13c551be1a45f",
      "7ee1fad10fd046ee8313a374bae75198",
      "094cf58c009945769123538ad4a58551",
      "078a2ab3d5b246558f90698313c7d4d9",
      "40119725db9940a0b6eb9ea52cb5354e",
      "15fa3fdb55aa46fbbb6cff619ca1f994",
      "6b878521bc1f4219b9122d9da8dcd162",
      "42a443cff0fd4aaa9c8c5fd45d188c6a",
      "9928118b0d744028a88224e5532d1238",
      "7aa1208ae12e4ffcb6366746b33f668b",
      "923c9982958943b8b8d7d92506298fcc",
      "0b0a8cd892cf4371862a51082ffe6834",
      "4bdbd59735ec4a5fa0f1d969c6ca55c8",
      "0a004049b79d426aad7a7a8aeddfa517",
      "819636097c934741adadea4010a44341",
      "61d82f3e800f4356869eca6eee22d759",
      "6691376945fa4745939858a10061d484",
      "a8e53329251443718ec8638183fde610",
      "ef567a64f1f54d30b801d8573c6c587c",
      "bd44a2a135064954b3733abe6b27266d",
      "19ca0d4efc52495583941d2c718f1091",
      "a99c542af627477dac6d895b81f25919",
      "f404f0c83bcd47c583ec789d2250c196",
      "7e468715233c459aa1b18d3564f3d4a4",
      "3d097039b26e4f7a8d7aecd25a035ad9",
      "d8ffbcff7b204b4f9d152d3b71106515",
      "63fae482415447a6b4dbf6db069f27b5",
      "036d30d1cdfd480ba328981c1aa26102",
      "3d8e67afb6354a80922607a35ead3eb9",
      "cfb0dd8272a048fca71b21abeda38988",
      "ad587d09a54740ab988a2278609aca42",
      "0aaad2622c51461683e9cb9c83f68d74",
      "aaf076331a07452b9aef38fb58ea75c0",
      "abd7968480be4c1d824a382e2ca19478",
      "ba2291e4e1964d049605e8af4012a767",
      "1939994109a84bef822433926a1c6d2a",
      "fd2a19e24682476096d47f85fd389c30",
      "9fb0f253ceba4dbfbcaa0708515ce3a2"
     ]
    },
    "collapsed": true,
    "id": "pCRP2my0tTEd",
    "outputId": "4eaf1d2c-c8e2-4567-841e-a120a1107e2e"
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Cargar modelo para embeddings\n",
    "embed_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Crear y almacenar los embeddings\n",
    "reviews_df[\"Embeddings\"] = embed_model.encode(reviews_df[\"Conversation\"].tolist()).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SyxoVnzbtuw0"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "def buscar_reviews(query, sentimiento=None, top_n=2):\n",
    "    # Obtener embedding del query\n",
    "    query_vec = embed_model.encode([query])\n",
    "\n",
    "    # Filtrar por sentimiento si se indica\n",
    "    if sentimiento:\n",
    "        df_filtrado = reviews_df[reviews_df[\"Sentiment\"] == sentimiento.upper()].copy()\n",
    "    else:\n",
    "        df_filtrado = reviews_df.copy()\n",
    "\n",
    "    # Si no hay reviews que coincidan con el filtro\n",
    "    if df_filtrado.empty:\n",
    "        print(\"No se encontraron rese√±as con ese sentimiento.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Asegurar que las columnas de embeddings est√©n en formato de matriz\n",
    "    embedding_matrix = np.vstack(df_filtrado[\"Embeddings\"].values)\n",
    "\n",
    "    # Calcular similitud coseno\n",
    "    similitudes = cosine_similarity(query_vec, embedding_matrix)[0]\n",
    "\n",
    "    # Obtener los top_n resultados m√°s similares\n",
    "    top_idx = np.argsort(similitudes)[-top_n:][::-1]\n",
    "    resultados = df_filtrado.iloc[top_idx].copy()\n",
    "    resultados[\"Similitud\"] = similitudes[top_idx]\n",
    "\n",
    "    return resultados[[\"Conversation\", \"Sentiment\", \"Similitud\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 112
    },
    "id": "IedAi506t1JS",
    "outputId": "46051739-03ca-4878-eee3-e19cc55bb368"
   },
   "outputs": [],
   "source": [
    "buscar_reviews(\"Great game components and rules\", sentimiento=\"POSITIVE\", top_n=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LnX9XrbdvPXh"
   },
   "source": [
    "## EJERCICIO 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WwbZbnSF7tN6"
   },
   "source": [
    "###Carga del set de datos (300 preguntas categorizadas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ih7rWkdFvRug",
    "outputId": "a69f2ea6-f641-432b-e6fe-6a3950437d33"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('/content/preguntas_tiny_towns (1).csv')\n",
    "\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q4ZN9Ob54O_n",
    "outputId": "6fed3b5a-3977-474a-d580-b932e7b052b0"
   },
   "outputs": [],
   "source": [
    "# Contar cu√°ntas preguntas hay de cada categor√≠a\n",
    "conteo_categorias = df['Categor√≠a'].value_counts()\n",
    "\n",
    "print(conteo_categorias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bPyIO9SL5gIV"
   },
   "outputs": [],
   "source": [
    "df.columns = df.columns.str.strip().str.lower()\n",
    "df.rename(columns={'pregunta': 'pregunta', 'categor√≠a': 'categoria'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vtK01MoUqIVn"
   },
   "source": [
    "### Modelo de Clasificaci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3DF-QNNH-xmX",
    "outputId": "65f4e677-e568-4696-e4b0-1feca380fd0c"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report\n",
    "\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "import gensim.utils\n",
    "\n",
    "\n",
    "X = df['pregunta'].values\n",
    "y = df['categor√≠a'].values\n",
    "\n",
    "# Divisi√≥n train-test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\n",
    "\n",
    "# TF-IDF + LogisticRegression\n",
    "\n",
    "# Vectorizar texto con TF-IDF\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "# Entrenar LR\n",
    "lr_tfidf = LogisticRegression(max_iter=1000)\n",
    "lr_tfidf.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Predecir\n",
    "y_pred_tfidf = lr_tfidf.predict(X_test_tfidf)\n",
    "\n",
    "# M√©tricas TF-IDF\n",
    "print(\"*TF-IDF + Logistic Regression\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_tfidf))\n",
    "print(\"F1-score:\", f1_score(y_test, y_pred_tfidf, average='weighted'))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_tfidf, average='weighted'))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_tfidf, average='weighted'))\n",
    "print(\"\\nReporte de clasificaci√≥n:\\n\", classification_report(y_test, y_pred_tfidf))\n",
    "\n",
    "# Predicci√≥n consulta nueva con TF-IDF\n",
    "consulta = [\"¬øquien invento tiny towns?\"]\n",
    "consulta_vec = tfidf_vectorizer.transform(consulta)\n",
    "print(consulta)\n",
    "print(\"Predicci√≥n TF-IDF:\", lr_tfidf.predict(consulta_vec))\n",
    "\n",
    "\n",
    "#Doc2Vec + LogisticRegression\n",
    "\n",
    "# Preparar documentos etiquetados\n",
    "train_tagged = [TaggedDocument(words=gensim.utils.simple_preprocess(doc), tags=[str(i)]) for i, doc in enumerate(X_train)]\n",
    "\n",
    "# Entrenar modelo Doc2Vec\n",
    "doc2vec_model = Doc2Vec(vector_size=50, min_count=2, epochs=40)\n",
    "doc2vec_model.build_vocab(train_tagged)\n",
    "doc2vec_model.train(train_tagged, total_examples=doc2vec_model.corpus_count, epochs=doc2vec_model.epochs)\n",
    "\n",
    "# Funci√≥n para vectorizar textos con Doc2Vec\n",
    "def doc2vec_vectorize(texts):\n",
    "    return [doc2vec_model.infer_vector(gensim.utils.simple_preprocess(text)) for text in texts]\n",
    "\n",
    "X_train_d2v = doc2vec_vectorize(X_train)\n",
    "X_test_d2v = doc2vec_vectorize(X_test)\n",
    "\n",
    "# Entrenar LR con vectores Doc2Vec\n",
    "lr_d2v = LogisticRegression(max_iter=1000)\n",
    "lr_d2v.fit(X_train_d2v, y_train)\n",
    "\n",
    "# Predecir\n",
    "y_pred_d2v = lr_d2v.predict(X_test_d2v)\n",
    "\n",
    "# M√©tricas Doc2Vec\n",
    "print(\"\\n*Doc2Vec + Logistic Regression\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_d2v))\n",
    "print(\"F1-score:\", f1_score(y_test, y_pred_d2v, average='weighted'))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_d2v, average='weighted'))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_d2v, average='weighted'))\n",
    "print(\"\\nReporte de clasificaci√≥n:\\n\", classification_report(y_test, y_pred_d2v))\n",
    "\n",
    "# Predicci√≥n consulta nueva con Doc2Vec\n",
    "consulta_d2v = doc2vec_vectorize(consulta)\n",
    "print(consulta)\n",
    "print(\"Predicci√≥n Doc2Vec:\", lr_d2v.predict(consulta_d2v))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "PC5-0IITx7W_",
    "iIAAWkhfycYz",
    "QAu5yvTpywIM",
    "6t5m7X731s2f",
    "nlSccxiTFWbk",
    "UOCmN_ZqGwtl",
    "_j6ube6SHr0f",
    "Dax0ul5pIfOx",
    "0IAtzv45F3zs",
    "pgdWSsBsF-kW",
    "jGnc1t6pGHg8",
    "cOoYcGPrGV-I",
    "0nsN-b1OgkVx",
    "JwlvCLn5gsms",
    "l3MTvl4OjEnE",
    "bOU3TTiAoCsc",
    "4k4uwNY_r6JL",
    "aK9Icf_AteaQ",
    "4HZ_dhsFtkbD",
    "LnX9XrbdvPXh",
    "WwbZbnSF7tN6",
    "vtK01MoUqIVn"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
